[{"categories":["转载","K8S"],"content":"转载，原为老男孩教育视频内容","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"01_K8S_概念入门 k8s概念入门 ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:0:0","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"1. 四组基本概念 Pod/Pod控制器 Name/Namespace Lable/Label选择器 Service/Ingress ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:1:0","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"1.1 POD和POD控制器 kubernetes 的pod控制器 Podk8s里能够被运行的最小逻辑单元1个POD里面可以运行多个容器(SideCar 边车模式)POD中的容器共享 UTS/NAT/IPC 名称空间POD和容器颗粒理解为豌豆荚和豌豆 Pod控制器Pod控制器是Pod启动的一种模板用来保证在K8S里启动的Pod始终按预期运行包括副本数\\生命周期\\健康检查等 常用的Pod控制器: 控制器名称 用途简述 Deployment 用于管理无状态应用,支持滚动更新和回滚 DaemonSet 确保集群中的每一个节点上只运行一个特定的pod副本 ReplicaSet 确保pod副本数量符合用户期望的数量状态 StatefulSet 管理有状态应用 Job 有状态，一次性任务 Cronjob(定时任务) 有状态，周期性任务 ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:1:1","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"1.2 Name/Namespace NameK8S使用’资源’来定义每一种逻辑概念(功能)每种’资源’都应该有自己的’名称'‘名称’通常定义在’资源’的元数据(metadata)信息中 资源的配置信息包括: API版本(apiVersion) 类别(kind) 元数据(metadata) 定义清单(spec) 状态(status) Namespace名称空间用于隔离K8S内各种资源,类似K8S内部的虚拟分组同一个名称空间中,相同资源的名称不能相同默认的名称空间为﻿default﻿，﻿kube-system﻿，﻿kube-public﻿查询特定资源,要带上相应的名称空间 ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:1:2","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"1.3 Lable/Label选择器 Lable标签的作用是便于分类管理资源对象标签与资源之间是多对多的关系给一个资源多个标签,可以实现不同维度的管理 Lable选择器可以使用标签选择器过滤指定的标签标签选择器有基于等值关系(等于,不等于)和基于集合关系(属于,存在)的两种许多资源都支持内嵌标签选择器字段:﻿matchLables﻿或﻿matchExpressions﻿ ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:1:3","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"1.4 Service/Ingress Service(重点)：POD会分配IP地址,但IP会随着POD销毁而消失多个同类型POD,IP或端口必然不同,但却相同的服务Service用来提供相同服务POD的对外访问接口Service通过标签选择器来确定作用于哪些PODService只能提供L4层的调度,即:IP+端口 Ingress(重点)：Ingress也是用来暴露POD的对外访问接口Igress提供L7层的调度,即http/httpsIgress可以调度不同业务域,不同URL路径的流量 ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:1:4","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"2. 核心组件与核心附件 核心组件配置存储中心 etcd服务 主控节点（master） kube-apiserver服务 kube-controller-manager服务 kube-scheduler服务 运算节点（node） kube-kubelet服务 kube-proxy服务 CLI客户端kubectl命令行工具 核心附件CNI网络插件（flannel/calico） 服务发现插件（coredns） 服务暴露插件（traefik） GUI管理插件（dashboard） ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:2:0","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"2.1 核心组件功能 配置存储中心-etcdetcd是一个非关系型数据库，作用类似于zookeeper注册中心用于各种服务的注册和数据缓存 kube-apiserver(master)提供季军管理的REST API接口，包括鉴权、数据校验、集群状态变更负责其他模块之间的数据交互，承担通信枢纽的功能和etcd通信，是资源配额控制的入口提供玩备的集群控制机制 kube-controller-manager由一系列控制器组成,通过apiserver监控整个集群的状态,确保集群处于预期的工作状态是管理所有控制器的控制器 kube-scheduler主要是接收调度POD到合适的node节点上通过apiserver，从etcd中获取资源信息进行调度只负责调度工作，启动工作是node节点上的kubelet负责调度策略：预算策略（predict）、优选策略（priorities） kube-kubelet定时从apiserver获取节点上POD的期望状态（如副本数量、网络类型、存储空间、容器类型等）然后调用容器平台接口达到这个状态提供POD节点具体使用的网络定时汇报当前节点状态给apiserver，以供调度复制镜像和容器的创建和清理工作 kube-proxy是K8S在每个节点上运行网络的代理，service资源的载体不直接为POD节点提供网络,而是提供POD间的集群网络建立了POD网络和集群网络的关系（clusterIp-\u003epodIp)负责建立、删除、更新调度规则与apiserver通信，以更新自己和获取其他kube-proxy的的调度规则常用的调度模式：Iptables(不推荐)、Ipvs(推荐) ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:2:1","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"2.2 K8S的三条网络 节点网络实际网络，就是宿主机网络建议地址段：﻿10.4.7.0/24﻿建议通过不同的IP端,区分不同的业务、机房或数据中心 Pod 网络实际网络，容器运行的网络建议﻿172.7.21.0/24﻿ ,并建议POD网段与节点IP绑定如: 节点IP为﻿10.4.7.21﻿，则POD网络为﻿172.7.21.0/24﻿ service网络虚拟网络，也叫集群网络(cluster server),用于内部集群间通信构建于POD网络之上, 主要是解决服务发现和负载均衡通过kube-proxy连接POD网络和service网络建议地址段为：﻿192.168.0.0/16﻿ ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:2:2","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["转载","K8S"],"content":"3. K8S流程图 说明: 主控节点和node节点只是逻辑上的概念,物理上可以部署在一起 ","date":"2020-10-01","objectID":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/:3:0","tags":["K8S","转载"],"title":"01_K8S_概念入门","uri":"/01_k8s_%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"categories":["K8S","转载"],"content":"02_K8S二进制部署实践-1.15.5 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:0:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"1. 部署架构 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:1:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"1.1 架构图 架构说明: etcd至少3台组成一个高可用集群 两台proxy组成高可用代理对外提供VIP 两台机器共同承担master和node节点功能 运维主机非K8S套件,但为K8S服务 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:1:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"1.2 安装方式选择 Minikube 预览使用,仅供学习 二进制安装(生产首选,新手推荐) kubeadmin安装 简单,用k8s跑k8s自己,熟手推荐 新手不推荐的原因是容易知其然不知其所以然 出问题后找不到解决办法 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:1:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2. 部署准备 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.1 准备工作 准备5台2C/2g/50g虚拟机,网络10.4.7.0/24 预装centos7.4,做完基础优化 安装部署bind9,部署自建DNS系统 准备自签证书环境 安装部署docker和harbor仓库 机器列表 主机名 IP地址 用途 hdss7-11 10.4.7.11 proxy1 hdss7-12 10.4.7.12 proxy2 hdss7-21 10.4.7.21 master1 hdss7-22 10.4.7.22 master2 hdss7-200 10.4.7.200 运维主机 基本部署软件 [root@hdss7-11 ~]# hostname hdss7-11 [root@hdss7-11 ~]# getenforce Disabled [root@hdss7-11 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=Ethernet BOOTPROTO=none NAME=eth0 DEVICE=eth0 ONBOOT=yes IPADDR=10.4.7.11 NETMASK=255.255.255.0 GATEWAY=10.4.7.254 DNS1=10.4.7.254 [root@hdss7-11 ~]# yum install wget net-tools telnet tree nmap sysstat lrzsz dos2unix -y ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.2 部署DNS服务bind9 2.2.1 安装配置DNS服务 在7.11上部署bind的DNS服务 yum install bind bind-utils -y 修改并校验配置文件 [root@hdss7-11 ~]# vim /etc/named.conf listen-on port 53 { 10.4.7.11; }; allow-query { any; }; forwarders { 10.4.7.254; }; #上一层DNS地址(网关或公网DNS) recursion yes; dnssec-enable no; dnssec-validation no [root@hdss7-11 ~]# named-checkconf 2.2.2 增加自定义域和对于配置 在域配置中增加自定义域 cat \u003e\u003e/etc/named.rfc1912.zones \u003c\u003c'EOF' # 添加自定义主机域 zone \"host.com\" IN { type master; file \"host.com.zone\"; allow-update { 10.4.7.11; }; }; # 添加自定义业务域 zone \"zq.com\" IN { type master; file \"zq.com.zone\"; allow-update { 10.4.7.11; }; }; EOF host.com和zq.com都是我们自定义的域名,一般用host.com做为主机域 zq.com为业务域,业务不同可以配置多个 为自定义域host.com创建配置文件 cat \u003e/var/named/host.com.zone \u003c\u003c'EOF' $ORIGIN host.com. $TTL 600 ; 10 minutes @ IN SOA dns.host.com. dnsadmin.host.com. ( 2020041601 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.host.com. $TTL 60 ; 1 minute dns A 10.4.7.11 HDSS7-11 A 10.4.7.11 HDSS7-12 A 10.4.7.12 HDSS7-21 A 10.4.7.21 HDSS7-22 A 10.4.7.22 HDSS7-200 A 10.4.7.200 EOF 为自定义域zq.com创建配置文件 cat \u003e/var/named/zq.com.zone \u003c\u003c'EOF' $ORIGIN zq.com. $TTL 600 ; 10 minutes @ IN SOA dns.zq.com. dnsadmin.zq.com. ( 2020041601 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.zq.com. $TTL 60 ; 1 minute dns A 10.4.7.11 EOF host.com域用于主机之间通信,所以要先增加上所有主机 zq.com域用于后面的业务解析用,因此不需要先添加主机 2.2.3 启动并验证DNS服务 再次检查配置并启动dns服务 [root@hdss7-11 ~]# named-checkconf [root@hdss7-11 ~]# systemctl start named [root@hdss7-11 ~]# ss -lntup|grep 53 udp UNCONN 0 0 10.4.7.11:53 udp UNCONN 0 0 :::53 tcp LISTEN 0 10 10.4.7.11:53 tcp LISTEN 0 128 127.0.0.1:953 tcp LISTEN 0 10 :::53 tcp LISTEN 0 128 ::1:953 # 验证结果 [root@hdss7-11 ~]# dig -t A hdss7-11.host.com @10.4.7.11 +short 10.4.7.11 [root@hdss7-11 ~]# dig -t A hdss7-21.host.com @10.4.7.11 +short 10.4.7.21 2.2.4 所有主机修改网络配置 5台K8S主机都需要按如下方式修改网络配置 # 修改dns并添加搜索域 sed -i 's#^DNS.*#DNS1=10.4.7.11#g' /etc/sysconfig/network-scripts/ifcfg-eth0 echo \"search=host.com\" \u003e\u003e/etc/sysconfig/network-scripts/ifcfg-eth0 systemctl restart network # 检查DNS配置 ~]# cat /etc/resolv.conf # Generated by NetworkManager search host.com nameserver 10.4.7.11 ~]# dig -t A hdss7-21.host.com +short 10.4.7.21 # 一定记得检查dns配置文件中是否有search信息 windows宿主机也要改 wmnet8网卡更改DNS：10.4.7.11 # ping通才行,否则检查 ping hdss7-200.host.com ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.3 自签发证书环境准备 操作在7.200这个运维机上完成 2.3.1 下载安装cfssl wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/bin/cfssl wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O /usr/bin/cfssl-json wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -O /usr/bin/cfssl-certinfo chmod +x /usr/bin/cfssl* 2.3.2 生成ca证书文件 mkdir /opt/certs cat \u003e/opt/certs/ca-csr.json \u003c\u003cEOF { \"CN\": \"zqcd\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"chengdu\", \"L\": \"chengdu\", \"O\": \"zq\", \"OU\": \"ops\" } ], \"ca\": { \"expiry\": \"175200h\" } } EOF CN: Common Name，浏览器使用该字段验证网站是否合法，一般写的是域名。非常重要。浏览器使用该字段验证网站是否合法 C: Country， 国家 ST: State，州，省 L: Locality，地区，城市 O: Organization Name，组织名称，公司名称 OU: Organization Unit Name，组织单位名称，公司部门 2.3.3 生成ca证书 cd /opt/certs cfssl gencert -initca ca-csr.json | cfssl-json -bare ca [root@hdss7-200 certs]# ll total 16 -rw-r--r-- 1 root root 989 Apr 16 20:53 cacsr -rw-r--r-- 1 root root 324 Apr 16 20:52 ca-csr.json -rw------- 1 root root 1679 Apr 16 20:53 ca-key.pem -rw-r--r-- 1 root root 1330 Apr 16 20:53 ca.pem ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:3","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.4 docker环境准备 2.4.1 安装并配置docker curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun mkdir /etc/docker/ cat \u003e/etc/docker/daemon.json \u003c\u003cEOF { \"graph\": \"/data/docker\", \"storage-driver\": \"overlay2\", \"insecure-registries\": [\"registry.access.redhat.com\",\"quay.io\",\"harbor.zq.com\"], \"registry-mirrors\": [\"https://q2gr04ke.mirror.aliyuncs.com\"], \"bip\": \"172.7.21.1/24\", \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"live-restore\": true } EOF 注意:bip要根据宿主机ip变化 hdss7-21.host.com bip 172.7.21.1/24 hdss7-22.host.com bip 172.7.22.1/24 hdss7-200.host.com bip 172.7.200.1/24 2.4.2 启动docker mkdir -p /data/docker systemctl start docker systemctl enable docker docker --version ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:4","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.5 部署harbor私有仓库 下载地址:https://github.com/goharbor/harbor/releases/download/v1.8.5/harbor-offline-installer-v1.8.5.tgz 2.5.1 下载并解压 tar xf harbor-offline-installer-v1.8.5.tgz -C /opt/ cd /opt/ mv harbor/ harbor-v1.8.5 ln -s /opt/harbor-v1.8.5/ /opt/harbor 2.5.2 编辑配置文件 [root@hdss7-200 opt]# vi /opt/harbor/harbor.yml # 以下是修改项,手动在配置文件中更改 hostname: harbor.zq.com http: port: 180 harbor_admin_password:Harbor12345 data_volume: /data/harbor log: level: info rotate_count: 50 rotate_size:200M location: /data/harbor/logs [root@hdss7-200 opt]# mkdir -p /data/harbor/logs 2.5.3 使用docker-compose启动harbor [root@hdss7-200 opt]cd /opt/harbor/ yum install docker-compose -y sh /opt/harbor/install.sh docker-compose ps docker ps -a 2.5.4 使用dns解析harbor 在7.11DNS服务上操作 [root@hdss7-11 ~]# vi /var/named/zq.com.zone 2020032002 ; serial #每次修改DNS解析后,都要滚动此ID harbor A 10.4.7.200 [root@hdss7-11 ~]# systemctl restart named [root@hdss7-11 ~]# dig -t A harbor.zq.com +short 10.4.7.200 2.5.5 使用nginx反向代理harbor 回到7.200运维机上操作 [root@hdss7-200 harbor]# yum install nginx -y [root@hdss7-200 harbor]# vi /etc/nginx/conf.d/harbor.zq.com.conf server { listen 80; server_name harbor.zq.com; client_max_body_size 1000m; location / { proxy_pass http://127.0.0.1:180; } } [root@hdss7-200 harbor]# nginx -t [root@hdss7-200 harbor]# systemctl start nginx [root@hdss7-200 harbor]# systemctl enable nginx 浏览器输入：harbor.zq.com 用户名：admin 密码：Harbor12345 新建项目：public 访问级别：公开 2.5.6 提前准备pauser/nginx基础镜像 pauser镜像是k8s启动pod时,预先用来创建相关资源(如名称空间)的 nginx镜像是k8s部署好以后,我们测试pod创建所用的 docker login harbor.zq.com -uadmin -pHarbor12345 docker pull kubernetes/pause docker pull nginx:1.17.9 docker tag kubernetes/pause:latest harbor.zq.com/public/pause:latest docker tag nginx:1.17.9 harbor.zq.com/public/nginx:v1.17.9 docker push harbor.zq.com/public/pause:latest docker push harbor.zq.com/public/nginx:v1.17.9 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:5","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"2.6 准备nginx文件服务 创建一个nginx虚拟主机,用来提供文件访问访问,主要依赖nginx的autoindex属性 2.6.1 创建文件访问 在7.200上 # 创建配置 cat \u003e/etc/nginx/conf.d/k8s-yaml.zq.com.conf \u003c\u003cEOF server { listen 80; server_name k8s-yaml.zq.com; location / { autoindex on; default_type text/plain; root /data/k8s-yaml; } } EOF # 启动nginx mkdir -p /data/k8s-yaml/coredns nginx -t nginx -s reload 2.6.2 添加域名解析 在7.11的bind9域名服务器上,增加DNS记录 vi /var/named/zq.com.zone # 在最后添加一条解析记录 k8s-yaml A 10.4.7.200 # 同时滚动serial为 @ IN SOA dns.zq.com. dnsadmin.zq.com. ( 2019061803 ; serial 重启服务并验证: systemctl restart named [root@hdss7-11 ~]# dig -t A k8s-yaml.zq.com +short 10.4.7.200 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:2:6","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"3. 部署master节点-etcd服务 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:3:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"3.1 部署etcd集群 分别在12/21/22 上安装ectd服务,11节点作为备选节点 3.1.1 创建生成CA证书的JSON配置文件 在7.200上操作 一个配置里面包含了server端,clinet端和双向(peer)通信所需要的配置,后面创建证书的时候会传入不同的参数调用不同的配置 cat \u003e/opt/certs/ca-config.json \u003c\u003cEOF { \"signing\": { \"default\": { \"expiry\": \"175200h\" }, \"profiles\": { \"server\": { \"expiry\": \"175200h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\" ] }, \"client\": { \"expiry\": \"175200h\", \"usages\": [ \"signing\", \"key encipherment\", \"client auth\" ] }, \"peer\": { \"expiry\": \"175200h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } } } EOF 证书时间统一为10年,不怕过期 证书类型 client certificate：客户端使用，用于服务端认证客户端,例如etcdctl、etcd proxy、fleetctl、docker客户端 server certificate：服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver peer certificate：双向证书，用于etcd集群成员间通信 3.1.3.创建生成自签发请求(csr)的json配置文件 注意: 需要将所有可能用来部署etcd的机器,都加入到hosts列表中 否则后期重新加入不在列表中的机器,需要更换所有etcd服务的证书 cat \u003e/opt/certs/etcd-peer-csr.json \u003c\u003cEOF { \"CN\": \"k8s-etcd\", \"hosts\": [ \"127.0.0.1\", \"10.4.7.11\", \"10.4.7.12\", \"10.4.7.21\", \"10.4.7.22\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"beijing\", \"L\": \"beijing\", \"O\": \"zq\", \"OU\": \"ops\" } ] } EOF 3.1.4.生成etcd证书文件 cd /opt/certs/ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem \\ -config=ca-config.json -profile=peer \\ etcd-peer-csr.json |cfssl-json -bare etcd-peer [root@hdss7-200 certs]# ll total 36 -rw-r--r-- 1 root root 837 Apr 19 15:35 ca-config.json -rw-r--r-- 1 root root 989 Apr 16 20:53 ca.csr -rw-r--r-- 1 root root 324 Apr 16 20:52 ca-csr.json -rw------- 1 root root 1679 Apr 16 20:53 ca-key.pem -rw-r--r-- 1 root root 1330 Apr 16 20:53 ca.pem -rw-r--r-- 1 root root 1062 Apr 19 15:35 etcd-peer.csr -rw-r--r-- 1 root root 363 Apr 19 15:35 etcd-peer-csr.json -rw------- 1 root root 1679 Apr 19 15:35 etcd-peer-key.pem -rw-r--r-- 1 root root 1419 Apr 19 15:35 etcd-peer.pem ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:3:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"3.2 安装启动etcd集群 以7.12做为演示,另外2台机器大同小异,不相同的配置都会特别说明 3.2.1 创建etcd用户和安装软件 etcd地址:https://github.com/etcd-io/etcd/tags 建议使用3.1版本,更高版本有问题 useradd -s /sbin/nologin -M etcd wget https://github.com/etcd-io/etcd/archive/v3.1.20.tar.gz tar xf etcd-v3.1.20-linux-amd64.tar.gz -C /opt/ cd /opt/ mv etcd-v3.1.20-linux-amd64/ etcd-v3.1.20 ln -s /opt/etcd-v3.1.20/ /opt/etcd 3.2.2 创建目录，拷贝证书文件 创建证书目录、数据目录、日志目录 mkdir -p /opt/etcd/certs /data/etcd /data/logs/etcd-server chown -R etcd.etcd /opt/etcd-v3.1.20/ chown -R etcd.etcd /data/etcd/ chown -R etcd.etcd /data/logs/etcd-server/ 拷贝生成的证书文件 cd /opt/etcd/certs scp hdss7-200:/opt/certs/ca.pem . scp hdss7-200:/opt/certs/etcd-peer.pem . scp hdss7-200:/opt/certs/etcd-peer-key.pem . chown -R etcd.etcd /opt/etcd/certs 也可以先创建一个NFS,直接从NFS中拷贝 3.2.3 创建etcd服务启动脚本 参数说明: https://blog.csdn.net/kmhysoft/article/details/71106995 cat \u003e/opt/etcd/etcd-server-startup.sh \u003c\u003c'EOF' #!/bin/sh ./etcd \\ --name etcd-server-7-12 \\ --data-dir /data/etcd/etcd-server \\ --listen-peer-urls https://10.4.7.12:2380 \\ --listen-client-urls https://10.4.7.12:2379,http://127.0.0.1:2379 \\ --quota-backend-bytes 8000000000 \\ --initial-advertise-peer-urls https://10.4.7.12:2380 \\ --advertise-client-urls https://10.4.7.12:2379,http://127.0.0.1:2379 \\ --initial-cluster etcd-server-7-12=https://10.4.7.12:2380,etcd-server-7-21=https://10.4.7.21:2380,etcd-server-7-22=https://10.4.7.22:2380 \\ --ca-file ./certs/ca.pem \\ --cert-file ./certs/etcd-peer.pem \\ --key-file ./certs/etcd-peer-key.pem \\ --client-cert-auth \\ --trusted-ca-file ./certs/ca.pem \\ --peer-ca-file ./certs/ca.pem \\ --peer-cert-file ./certs/etcd-peer.pem \\ --peer-key-file ./certs/etcd-peer-key.pem \\ --peer-client-cert-auth \\ --peer-trusted-ca-file ./certs/ca.pem \\ --log-output stdout EOF [root@hdss7-12 ~]# chmod +x /opt/etcd/etcd-server-startup.sh 注意:以上启动脚本,有几个配置项在每个服务器都有所不同 --name #节点名字 --listen-peer-urls #监听其他节点所用的地址 --listen-client-urls #监听etcd客户端的地址 --initial-advertise-peer-urls #与其他节点交互信息的地址 --advertise-client-urls #与etcd客户端交互信息的地址 3.2.4 使用supervisor启动etcd 安装supervisor软件 yum install supervisor -y systemctl start supervisord systemctl enable supervisord 创建supervisor管理etcd的配置文件 配置说明参考: https://www.jianshu.com/p/53b5737534e8 cat \u003e/etc/supervisord.d/etcd-server.ini \u003c\u003cEOF [program:etcd-server] ; 显示的程序名,类型my.cnf,可以有多个 command=sh /opt/etcd/etcd-server-startup.sh numprocs=1 ; 启动进程数 (def 1) directory=/opt/etcd ; 启动命令前切换的目录 (def no cwd) autostart=true ; 是否自启 (default: true) autorestart=true ; 是否自动重启 (default: true) startsecs=30 ; 服务运行多久判断为成功(def. 1) startretries=3 ; 启动重试次数 (default 3) exitcodes=0,2 ; 退出状态码 (default 0,2) stopsignal=QUIT ; 退出信号 (default TERM) stopwaitsecs=10 ; 退出延迟时间 (default 10) user=etcd ; 运行用户 redirect_stderr=true ; 是否重定向错误输出到标准输出(def false) stdout_logfile=/data/logs/etcd-server/etcd.stdout.log stdout_logfile_maxbytes=64MB ; 日志文件大小 (default 50MB) stdout_logfile_backups=4 ; 日志文件滚动个数 (default 10) stdout_capture_maxbytes=1MB ; 设定capture管道的大小(default 0) ;子进程还有子进程,需要添加这个参数,避免产生孤儿进程 killasgroup=true stopasgroup=true EOF 启动etcd服务并检查 supervisorctl update supervisorctl status netstat -lntup|grep etcd 3.2.5 部署启动集群其他机器 略 3.2.6 检查集群状态 [root@hdss7-12 certs]# /opt/etcd/etcdctl cluster-health member 988139385f78284 is healthy: got healthy result from http://127.0.0.1:2379 member 5a0ef2a004fc4349 is healthy: got healthy result from http://127.0.0.1:2379 member f4a0cb0a765574a8 is healthy: got healthy result from http://127.0.0.1:2379 [root@hdss7-12 certs]# /opt/etcd/etcdctl member list 988139385f78284: name=etcd-server-7-22 peerURLs=https://10.4.7.22:2380 clientURLs=http://127.0.0.1:2379,https://10.4.7.22:2379 isLeader=false 5a0ef2a004fc4349: name=etcd-server-7-21 peerURLs=https://10.4.7.21:2380 clientURLs=http://127.0.0.1:2379,https://10.4.7.21:2379 isLeader=false f4a0cb0a765574a8: name=etcd-server-7-12 peerURLs=https://10.4.7.12:2380 clientURLs=http://127.0.0.1:2379,https://10.4.7.12:2379 isLeader=true ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:3:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4. 部署mater节点 kube-apiserver服务 下载页面: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.15.md 下载地址: https://dl.k8s.io/v1.15.5/kubernetes-server-linux-amd64.tar.gz https://dl.k8s.io/v1.15.5/kubernetes-client-linux-amd64.tar.gz https://dl.k8s.io/v1.15.5/kubernetes-node-linux-amd64.tar.gz ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.1 签发client端证书 证书签发都在7.200上操作 此证书的用途是apiserver和etcd之间通信所用 4.1.1 创建生成证书csr的json配置文件 cat \u003e/opt/certs/client-csr.json \u003c\u003cEOF { \"CN\": \"k8s-node\", \"hosts\": [ ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"beijing\", \"L\": \"beijing\", \"O\": \"zq\", \"OU\": \"ops\" } ] } EOF 4.1.2 生成client证书文件 cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=client \\ client-csr.json |cfssl-json -bare client [root@hdss7-200 certs]# ll|grep client -rw-r--r-- 1 root root 993 Apr 20 21:30 client.csr -rw-r--r-- 1 root root 280 Apr 20 21:30 client-csr.json -rw------- 1 root root 1675 Apr 20 21:30 client-key.pem -rw-r--r-- 1 root root 1359 Apr 20 21:30 client.pem ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.2 签发kube-apiserver证书 此证书的用途是apiserver对外提供的服务的证书 4.2.1 创建生成证书csr的json配置文件 此配置中的hosts包含所有可能会部署apiserver的列表 其中10.4.7.10是反向代理的vip地址 cat \u003e/opt/certs/apiserver-csr.json \u003c\u003cEOF { \"CN\": \"k8s-apiserver\", \"hosts\": [ \"127.0.0.1\", \"192.168.0.1\", \"kubernetes.default\", \"kubernetes.default.svc\", \"kubernetes.default.svc.cluster\", \"kubernetes.default.svc.cluster.local\", \"10.4.7.10\", \"10.4.7.21\", \"10.4.7.22\", \"10.4.7.23\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"beijing\", \"L\": \"beijing\", \"O\": \"zq\", \"OU\": \"ops\" } ] } EOF 4.2.2 生成kube-apiserver证书文件 cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=server \\ apiserver-csr.json |cfssl-json -bare apiserver [root@hdss7-200 certs]# ll|grep apiserver -rw-r--r-- 1 root root 1249 Apr 20 21:31 apiserver.csr -rw-r--r-- 1 root root 566 Apr 20 21:31 apiserver-csr.json -rw------- 1 root root 1675 Apr 20 21:31 apiserver-key.pem -rw-r--r-- 1 root root 1590 Apr 20 21:31 apiserver.pem ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.3 下载安装kube-apiserver 以7.21为例 # 上传并解压缩 tar xf kubernetes-server-linux-amd64-v1.15.2.tar.gz -C /opt cd /opt mv kubernetes/ kubernetes-v1.15.2 ln -s /opt/kubernetes-v1.15.2/ /opt/kubernetes # 清理源码包和docker镜像 cd /opt/kubernetes rm -rf kubernetes-src.tar.gz cd server/bin rm -f *.tar rm -f *_tag # 创建命令软连接到系统环境变量下 ln -s /opt/kubernetes/server/bin/kubectl /usr/bin/kubectl ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:3","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.4 部署apiserver服务 4.4.1 拷贝证书文件 拷贝证书文件到/opt/kubernetes/server/bin/cert目录下 # 创建目录 mkdir -p /opt/kubernetes/server/bin/cert cd /opt/kubernetes/server/bin/cert # 拷贝三套证书 scp hdss7-200:/opt/certs/ca.pem . scp hdss7-200:/opt/certs/ca-key.pem . scp hdss7-200:/opt/certs/client.pem . scp hdss7-200:/opt/certs/client-key.pem . scp hdss7-200:/opt/certs/apiserver.pem . scp hdss7-200:/opt/certs/apiserver-key.pem . 4.4.2 创建audit配置 audit日志审计规则配置是k8s要求必须要有得配置,可以不理解,直接用 mkdir /opt/kubernetes/server/conf cat \u003e/opt/kubernetes/server/conf/audit.yaml \u003c\u003c'EOF' apiVersion: audit.k8s.io/v1beta1 # This is required. kind: Policy # Don't generate audit events for all requests in RequestReceived stage. omitStages: - \"RequestReceived\" rules: # Log pod changes at RequestResponse level - level: RequestResponse resources: - group: \"\" # Resource \"pods\" doesn't match requests to any subresource of pods, # which is consistent with the RBAC policy. resources: [\"pods\"] # Log \"pods/log\", \"pods/status\" at Metadata level - level: Metadata resources: - group: \"\" resources: [\"pods/log\", \"pods/status\"] # Don't log requests to a configmap called \"controller-leader\" - level: None resources: - group: \"\" resources: [\"configmaps\"] resourceNames: [\"controller-leader\"] # Don't log watch requests by the \"system:kube-proxy\" on endpoints or services - level: None users: [\"system:kube-proxy\"] verbs: [\"watch\"] resources: - group: \"\" # core API group resources: [\"endpoints\", \"services\"] # Don't log authenticated requests to certain non-resource URL paths. - level: None userGroups: [\"system:authenticated\"] nonResourceURLs: - \"/api*\" # Wildcard matching. - \"/version\" # Log the request body of configmap changes in kube-system. - level: Request resources: - group: \"\" # core API group resources: [\"configmaps\"] # This rule only applies to resources in the \"kube-system\" namespace. # The empty string \"\" can be used to select non-namespaced resources. namespaces: [\"kube-system\"] # Log configmap and secret changes in all other namespaces at the Metadata level. - level: Metadata resources: - group: \"\" # core API group resources: [\"secrets\", \"configmaps\"] # Log all other resources in core and extensions at the Request level. - level: Request resources: - group: \"\" # core API group - group: \"extensions\" # Version of group should NOT be included. # A catch-all rule to log all other requests at the Metadata level. - level: Metadata # Long-running requests like watches that fall under this rule will not # generate an audit event in RequestReceived. omitStages: - \"RequestReceived\" EOF 4.4.3 创建apiserver启动脚本 cat \u003e/opt/kubernetes/server/bin/kube-apiserver.sh \u003c\u003c'EOF' #!/bin/bash ./kube-apiserver \\ --apiserver-count 2 \\ --audit-log-path /data/logs/kubernetes/kube-apiserver/audit-log \\ --audit-policy-file ../conf/audit.yaml \\ --authorization-mode RBAC \\ --client-ca-file ./cert/ca.pem \\ --requestheader-client-ca-file ./cert/ca.pem \\ --enable-admission-plugins NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota \\ --etcd-cafile ./cert/ca.pem \\ --etcd-certfile ./cert/client.pem \\ --etcd-keyfile ./cert/client-key.pem \\ --etcd-servers https://10.4.7.12:2379,https://10.4.7.21:2379,https://10.4.7.22:2379 \\ --service-account-key-file ./cert/ca-key.pem \\ --service-cluster-ip-range 192.168.0.0/16 \\ --service-node-port-range 3000-29999 \\ --target-ram-mb=1024 \\ --kubelet-client-certificate ./cert/client.pem \\ --kubelet-client-key ./cert/client-key.pem \\ --log-dir /data/logs/kubernetes/kube-apiserver \\ --tls-cert-file ./cert/apiserver.pem \\ --tls-private-key-file ./cert/apiserver-key.pem \\ --v 2 EOF # 授权 chmod +x /opt/kubernetes/server/bin/kube-apiserver.sh 4.4.4 创建supervisor启动apiserver的配置 安装supervisor软件 yum install supervisor -y systemctl start supervisord systemctl enable supervisord cat \u003e/etc/supervisord.d/kube-apiserver.ini \u003c\u003cEOF [program:kube-apiserver] ; 显示的程序名,类似my.cnf,可以有多个 command=sh /opt/kubernetes/server/bi","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:4","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.5 部署controller-manager服务 apiserve、controller-manager、kube-scheduler三个服务所需的软件在同一套压缩包里面的，因此后两个服务不需要在单独解包 而且这三个服务是在同一个主机上，互相之间通过http://127.0.0.1,也不需要证书 4.5.1 创建controller-manager启动脚本 cat \u003e/opt/kubernetes/server/bin/kube-controller-manager.sh \u003c\u003c'EOF' #!/bin/sh ./kube-controller-manager \\ --cluster-cidr 172.7.0.0/16 \\ --leader-elect true \\ --log-dir /data/logs/kubernetes/kube-controller-manager \\ --master http://127.0.0.1:8080 \\ --service-account-private-key-file ./cert/ca-key.pem \\ --service-cluster-ip-range 192.168.0.0/16 \\ --root-ca-file ./cert/ca.pem \\ --v 2 EOF # 授权 chmod +x /opt/kubernetes/server/bin/kube-controller-manager.sh 4.5.2 创建supervisor配置 cat \u003e/etc/supervisord.d/kube-conntroller-manager.ini \u003c\u003cEOF [program:kube-controller-manager] ; 显示的程序名 command=sh /opt/kubernetes/server/bin/kube-controller-manager.sh numprocs=1 ; 启动进程数 (def 1) directory=/opt/kubernetes/server/bin autostart=true ; 是否自启 (default: true) autorestart=true ; 是否自动重启 (default: true) startsecs=30 ; 服务运行多久判断为成功(def. 1) startretries=3 ; 启动重试次数 (default 3) exitcodes=0,2 ; 退出状态码 (default 0,2) stopsignal=QUIT ; 退出信号 (default TERM) stopwaitsecs=10 ; 退出延迟时间 (default 10) user=root ; 运行用户 redirect_stderr=true ; 重定向错误输出到标准输出(def false) stdout_logfile=/data/logs/kubernetes/kube-controller-manager/controller.stdout.log stdout_logfile_maxbytes=64MB ; 日志文件大小 (default 50MB) stdout_logfile_backups=4 ; 日志文件滚动个数 (default 10) stdout_capture_maxbytes=1MB ; 设定capture管道的大小(default 0) ;子进程还有子进程,需要添加这个参数,避免产生孤儿进程 killasgroup=true stopasgroup=true EOF 4.5.3 启动服务并检查 mkdir -p /data/logs/kubernetes/kube-controller-manager supervisorctl update supervisorctl status 4.5.4 部署启动所有集群 没有不同的地方,所以略 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:5","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.6 部署kube-scheduler服务 4.6.1 创建启动脚本 cat \u003e/opt/kubernetes/server/bin/kube-scheduler.sh \u003c\u003c'EOF' #!/bin/sh ./kube-scheduler \\ --leader-elect \\ --log-dir /data/logs/kubernetes/kube-scheduler \\ --master http://127.0.0.1:8080 \\ --v 2 EOF # 授权 chmod +x /opt/kubernetes/server/bin/kube-scheduler.sh 4.6.2 创建supervisor配置 cat \u003e/etc/supervisord.d/kube-scheduler.ini \u003c\u003cEOF [program:kube-scheduler] command=sh /opt/kubernetes/server/bin/kube-scheduler.sh numprocs=1 ; 启动进程数 (def 1) directory=/opt/kubernetes/server/bin autostart=true ; 是否自启 (default: true) autorestart=true ; 是否自动重启 (default: true) startsecs=30 ; 服务运行多久判断为成功(def. 1) startretries=3 ; 启动重试次数 (default 3) exitcodes=0,2 ; 退出状态码 (default 0,2) stopsignal=QUIT ; 退出信号 (default TERM) stopwaitsecs=10 ; 退出延迟时间 (default 10) user=root ; 运行用户 redirect_stderr=true ; 重定向错误输出到标准输出(def false) stdout_logfile=/data/logs/kubernetes/kube-scheduler/scheduler.stdout.log stdout_logfile_maxbytes=64MB ; 日志文件大小 (default 50MB) stdout_logfile_backups=4 ; 日志文件滚动个数 (default 10) stdout_capture_maxbytes=1MB ; 设定capture管道的大小(default 0) ;子进程还有子进程,需要添加这个参数,避免产生孤儿进程 killasgroup=true stopasgroup=true EOF 4.6.3 启动服务并检查 mkdir -p /data/logs/kubernetes/kube-scheduler supervisorctl update supervisorctl status 4.6.4 部署启动所有集群 没有不同的地方,所以略 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:6","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"4.7 检查master节点部署情况 [root@hdss7-21 bin]# kubectl get cs NAME STATUS MESSAGE ERROR controller-manager Healthy ok scheduler Healthy ok etcd-1 Healthy {\"health\": \"true\"} etcd-0 Healthy {\"health\": \"true\"} etcd-2 Healthy {\"health\": \"true\"} ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:4:7","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"5. 部署4层反代去代理apiserver master节点上的3套服务部署完成后,需要使用反向代理去统一两个apiservser的对外端口 这里使用nginx+keepalived的高可用架构部署在7.11和7.12两台机器上 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:5:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"5.1 部署nginx四层反代 使用7443端口代理apiserver的6443端口,使用keepalived管理VIP10.4.7.10 5.1.1 yum安装程序 yum install nginx keepalived -y 5.1.2 配置NGINX 四层代理不能写在默认的conf.d目录下,因为这个目录默认是数据http模块的include 所以要么把四层代理写到主配置文件最下面,要么模仿七层代理创建一个四层代理文件夹 # 1. 在nginx配置文件中增加四层代理配置文件夹 mkdir /etc/nginx/tcp.d/ echo 'include /etc/nginx/tcp.d/*.conf;' \u003e\u003e/etc/nginx/nginx.conf # 写入代理配置 cat \u003e/etc/nginx/tcp.d/apiserver.conf \u003c\u003cEOF stream { upstream kube-apiserver { server 10.4.7.21:6443 max_fails=3 fail_timeout=30s; server 10.4.7.22:6443 max_fails=3 fail_timeout=30s; } server { listen 7443; proxy_connect_timeout 2s; proxy_timeout 900s; proxy_pass kube-apiserver; } } EOF 5.1.3 启动nginx nginx -t systemctl start nginx systemctl enable nginx ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:5:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"5.2 配置keepalived 5.2.1 创建端口监测脚本 创建脚本 cat \u003e/etc/keepalived/check_port.sh \u003c\u003c'EOF' #!/bin/bash #keepalived 监控端口脚本 #使用方法：等待keepalived传入端口参数,检查改端口是否存在并返回结果 CHK_PORT=$1 if [ -n \"$CHK_PORT\" ];then PORT_PROCESS=`ss -lnt|grep $CHK_PORT|wc -l` if [ $PORT_PROCESS -eq 0 ];then echo \"Port $CHK_PORT Is Not Used,End.\" exit 1 fi else echo \"Check Port Cant Be Empty!\" fi EOF 给与脚本执行权限 chmod +x /etc/keepalived/check_port.sh 5.2.2 创建keepalived主配置文件 主机定义为10.4.7.11,从机定义为10.4.7.12 注意:主配置文件添加了nopreempt参数,非抢占式,意味着VIP发生漂移后,主重新启动后也不会夺回VIP,目的是为了稳定性 cat \u003e/etc/keepalived/keepalived.conf \u003c\u003c'EOF' ! Configuration File for keepalived global_defs { router_id 10.4.7.11 } vrrp_script chk_nginx { script \"/etc/keepalived/check_port.sh 7443\" interval 2 weight -20 } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 251 priority 100 advert_int 1 mcast_src_ip 10.4.7.11 nopreempt authentication { auth_type PASS auth_pass 11111111 } track_script { chk_nginx } virtual_ipaddress { 10.4.7.10 } } EOF 5.2.3 创建keepalived从配置文件 cat \u003e/etc/keepalived/keepalived.conf \u003c\u003c'EOF' ! Configuration File for keepalived global_defs { router_id 10.4.7.12 } vrrp_script chk_nginx { script \"/etc/keepalived/check_port.sh 7443\" interval 2 weight -20 } vrrp_instance VI_1 { state BACKUP interface eth0 virtual_router_id 251 mcast_src_ip 10.4.7.12 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 11111111 } track_script { chk_nginx } virtual_ipaddress { 10.4.7.10 } } EOF 5.3.4 启动keepalived并验证 systemctl start keepalived systemctl enable keepalived ip addr|grep '10.4.7.10' ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:5:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"6. 部署node节点 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:6:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"6.1 签发kubelet证书 签发证书,都在7.200上 6.1.1 创建生成证书csr的json配置文件 cd /opt/certs/ cat \u003e/opt/certs/kubelet-csr.json \u003c\u003cEOF { \"CN\": \"k8s-kubelet\", \"hosts\": [ \"127.0.0.1\", \"10.4.7.10\", \"10.4.7.21\", \"10.4.7.22\", \"10.4.7.23\", \"10.4.7.24\", \"10.4.7.25\", \"10.4.7.26\", \"10.4.7.27\", \"10.4.7.28\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"beijing\", \"L\": \"beijing\", \"O\": \"zq\", \"OU\": \"ops\" } ] } EOF 6.1.2 生成kubelet证书文件 cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=server \\ kubelet-csr.json | cfssl-json -bare kubelet [root@hdss7-200 certs]# ll |grep kubelet -rw-r--r-- 1 root root 1115 Apr 22 22:17 kubelet.csr -rw-r--r-- 1 root root 452 Apr 22 22:17 kubelet-csr.json -rw------- 1 root root 1679 Apr 22 22:17 kubelet-key.pem -rw-r--r-- 1 root root 1460 Apr 22 22:17 kubelet.pem ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:6:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"6.2 创建kubelet服务 6.2.1 拷贝证书至node节点 cd /opt/kubernetes/server/bin/cert scp hdss7-200:/opt/certs/kubelet.pem . scp hdss7-200:/opt/certs/kubelet-key.pem . 6.2.2 创建kubelet配置 创建kubelet的配置文件kubelet.kubeconfig比较麻烦,需要四步操作才能完成 (1) set-cluster(设置集群参数) 使用ca证书创建集群myk8s,使用的apiserver信息是10.4.7.10这个VIP cd /opt/kubernetes/server/conf/ kubectl config set-cluster myk8s \\ --certificate-authority=/opt/kubernetes/server/bin/cert/ca.pem \\ --embed-certs=true \\ --server=https://10.4.7.10:7443 \\ --kubeconfig=kubelet.kubeconfig (2) set-credentials(设置客户端认证参数) 使用client证书创建用户k8s-node kubectl config set-credentials k8s-node \\ --client-certificate=/opt/kubernetes/server/bin/cert/client.pem \\ --client-key=/opt/kubernetes/server/bin/cert/client-key.pem \\ --embed-certs=true \\ --kubeconfig=kubelet.kubeconfig (3) set-context(绑定namespace) 创建myk8s-context,关联集群myk8s和用户k8s-node kubectl config set-context myk8s-context \\ --cluster=myk8s \\ --user=k8s-node \\ --kubeconfig=kubelet.kubeconfig (4) use-context 使用生成的配置文件向apiserver注册,注册信息会写入etcd,所以只需要注册一次即可 kubectl config use-context myk8s-context --kubeconfig=kubelet.kubeconfig (5) 查看生成的kubelet.kubeconfig [root@hdss7-21 conf]# cat kubelet.kubeconfig apiVersion: v1 clusters: - cluster: certificate-authority-data: xxxxxxxx server: https://10.4.7.10:7443 name: myk8s contexts: - context: cluster: myk8s user: k8s-node name: myk8s-context current-context: myk8s-context kind: Config preferences: {} users: - name: k8s-node user: client-certificate-data: xxxxxxxx client-key-data: xxxxxxxx 可以看出来,这个配置文件里面包含了集群名字,用户名字,集群认证的公钥,用户的公私钥等 6.2.3 创建k8s-node.yaml配置文件 cat \u003e/opt/kubernetes/server/conf/k8s-node.yaml \u003c\u003cEOF apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: k8s-node roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:node subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: k8s-node EOF 使用RBAC鉴权规则,创建了一个ClusterRoleBinding的资源 此资源中定义了一个user叫k8s-node 给k8s-node用户绑定了角色ClusterRole,角色名为system:node 使这个用户具有成为集群运算节点角色的权限 由于这个用户名,同时也是kubeconfig中指定的用户, 所以通过kubeconfig配置启动的kubelet节点,就能够成为node节点 6.2.4 应用资源配置 应用资源配置,并查看结果 # 应用资源配置 kubectl create -f /opt/kubernetes/server/conf/k8s-node.yaml # 查看集群角色和角色属性 [root@hdss7-21 conf]# kubectl get clusterrolebinding k8s-node NAME AGE k8s-node 13s [root@hdss7-21 conf]# kubectl get clusterrolebinding k8s-node -o yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: creationTimestamp: \"2020-04-22T14:38:09Z\" name: k8s-node resourceVersion: \"21217\" selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/k8s-node uid: 597ffb0f-f92d-4eb5-aca2-2fe73397e2e4 roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:node subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: k8s-node #此时只是创建了相应的资源,还没有具体的node,如下验证 [root@hdss7-21 conf]# kubectl get nodes No resources found. 6.2.5 创建kubelet启动脚本 –hostname-override参数每个node节点都一样,是节点的主机名,注意修改 cat \u003e/opt/kubernetes/server/bin/kubelet.sh \u003c\u003c'EOF' #!/bin/sh ./kubelet \\ --hostname-override hdss7-21.host.com \\ --anonymous-auth=false \\ --cgroup-driver systemd \\ --cluster-dns 192.168.0.2 \\ --cluster-domain cluster.local \\ --runtime-cgroups=/systemd/system.slice \\ --kubelet-cgroups=/systemd/system.slice \\ --fail-swap-on=\"false\" \\ --client-ca-file ./cert/ca.pem \\ --tls-cert-file ./cert/kubelet.pem \\ --tls-private-key-file ./cert/kubelet-key.pem \\ --image-gc-high-threshold 20 \\ --image-gc-low-threshold 10 \\ --kubeconfig ../conf/kubelet.kubeconfig \\ --log-dir /data/logs/kubernetes/kube-kubelet \\ --pod-infra-container-image harbor.zq.com/public/pause:latest \\ --root-dir /data/kubelet EOF # 创建目录\u0026授权 chmod +x /opt/kubernetes/server/bin/kubelet.sh mkdir -p /data/logs/kubernetes/kube-kubelet mkdir -p /data/kubelet 6.2.6 创建supervisor配置 cat \u003e/etc/supervisord.d/kube-kubelet.ini \u003c\u003cEOF [program:kube-kubelet] command=sh /opt/kubernetes/server/bin/kubelet.sh numprocs=1 ; 启动进程数 (def 1) directory=/opt/kubernetes/server/bin autostart=true ; 是否自启 (default: true) autorestart=true ;","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:6:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"6.3 创建kube-proxy服务 签发证书在7.200上 6.3.1 签发kube-proxy证书 (1) 创建生成证书csr的json配置文件 cd /opt/certs/ cat \u003e/opt/certs/kube-proxy-csr.json \u003c\u003cEOF { \"CN\": \"system:kube-proxy\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"beijing\", \"L\": \"beijing\", \"O\": \"zq\", \"OU\": \"ops\" } ] } EOF (2) 生成kube-proxy证书文件 cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=client \\ kube-proxy-csr.json |cfssl-json -bare kube-proxy-client (3) 检查生成的证书文件 [root@hdss7-200 certs]# ll |grep proxy -rw-r--r-- 1 root root 1005 Apr 22 22:54 kube-proxy-client.csr -rw------- 1 root root 1675 Apr 22 22:54 kube-proxy-client-key.pem -rw-r--r-- 1 root root 1371 Apr 22 22:54 kube-proxy-client.pem -rw-r--r-- 1 root root 267 Apr 22 22:54 kube-proxy-csr.json 6.3.2 拷贝证书文件至各节点 cd /opt/kubernetes/server/bin/cert scp hdss7-200:/opt/certs/kube-proxy-client.pem . scp hdss7-200:/opt/certs/kube-proxy-client-key.pem . 6.3.3 创建kube-proxy配置 同样是四步操作,类似kubelet (1) set-cluster cd /opt/kubernetes/server/conf/ kubectl config set-cluster myk8s \\ --certificate-authority=/opt/kubernetes/server/bin/cert/ca.pem \\ --embed-certs=true \\ --server=https://10.4.7.10:7443 \\ --kubeconfig=kube-proxy.kubeconfig (2) set-credentials kubectl config set-credentials kube-proxy \\ --client-certificate=/opt/kubernetes/server/bin/cert/kube-proxy-client.pem \\ --client-key=/opt/kubernetes/server/bin/cert/kube-proxy-client-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfig (3) set-context kubectl config set-context myk8s-context \\ --cluster=myk8s \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfig (4) use-context kubectl config use-context myk8s-context --kubeconfig=kube-proxy.kubeconfig 6.3.4 加载ipvs模块以备kube-proxy启动用 # 创建开机ipvs脚本 cat \u003e/etc/ipvs.sh \u003c\u003c'EOF' #!/bin/bash ipvs_mods_dir=\"/usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs\" for i in $(ls $ipvs_mods_dir|grep -o \"^[^.]*\") do /sbin/modinfo -F filename $i \u0026\u003e/dev/null if [ $? -eq 0 ];then /sbin/modprobe $i fi done EOF # 执行脚本开启ipvs sh /etc/ipvs.sh # 验证开启结果 [root@hdss7-21 conf]# lsmod |grep ip_vs ip_vs_wrr 12697 0 ip_vs_wlc 12519 0 ......略 6.3.5 创建kube-proxy启动脚本 同上,–hostname-override参数在不同的node节点上不一样,需修改 cat \u003e/opt/kubernetes/server/bin/kube-proxy.sh \u003c\u003c'EOF' #!/bin/sh ./kube-proxy \\ --hostname-override hdss7-21.host.com \\ --cluster-cidr 172.7.0.0/16 \\ --proxy-mode=ipvs \\ --ipvs-scheduler=nq \\ --kubeconfig ../conf/kube-proxy.kubeconfig EOF # 授权 chmod +x /opt/kubernetes/server/bin/kube-proxy.sh 6.3.6 创建kube-proxy的supervisor配置 cat \u003e/etc/supervisord.d/kube-proxy.ini \u003c\u003c'EOF' [program:kube-proxy] command=sh /opt/kubernetes/server/bin/kube-proxy.sh numprocs=1 ; 启动进程数 (def 1) directory=/opt/kubernetes/server/bin autostart=true ; 是否自启 (default: true) autorestart=true ; 是否自动重启 (default: true) startsecs=30 ; 服务运行多久判断为成功(def. 1) startretries=3 ; 启动重试次数 (default 3) exitcodes=0,2 ; 退出状态码 (default 0,2) stopsignal=QUIT ; 退出信号 (default TERM) stopwaitsecs=10 ; 退出延迟时间 (default 10) user=root ; 运行用户 redirect_stderr=true ; 重定向错误输出到标准输出(def false) stdout_logfile=/data/logs/kubernetes/kube-proxy/proxy.stdout.log stdout_logfile_maxbytes=64MB ; 日志文件大小 (default 50MB) stdout_logfile_backups=4 ; 日志文件滚动个数 (default 10) stdout_capture_maxbytes=1MB ; 设定capture管道的大小(default 0) ;子进程还有子进程,需要添加这个参数,避免产生孤儿进程 killasgroup=true stopasgroup=true EOF 6.3.7 启动服务并检查 mkdir -p /data/logs/kubernetes/kube-proxy supervisorctl update supervisorctl status [root@hdss7-21 conf]# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 192.168.0.1 \u003cnone\u003e 443/TCP 47h # 检查ipvs,是否新增了配置 yum install ipvsadm -y [root@hdss7-21 conf]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u003e RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 192.168.0.1:443 nq -\u003e 10.4.7.21:6443 Masq 1 0 0 -\u003e 10.4.7.22:6443 Masq 1 0 0 6.3.8 部署所有节点 首先需拷贝kube-proxy.kubeconfig 到 hdss7-22.host.com的conf目录下 # 拷贝证书文件 cd /opt/kubernetes/server/bin/cert scp hdss7-200:/opt/certs/kube-proxy-client.pem . scp hdss7-20","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:6:3","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"7. 验证kubernetes集群 ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:7:0","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"7.1 在任意一个节点上创建一个资源配置清单 cat \u003e/root/nginx-ds.yaml \u003c\u003c'EOF' apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: nginx-ds spec: template: metadata: labels: app: nginx-ds spec: containers: - name: my-nginx image: harbor.zq.com/public/nginx:v1.17.9 ports: - containerPort: 80 EOF ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:7:1","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["K8S","转载"],"content":"7.2 应用资源配置，并检查 7.2.1 应用资源配置 kubectl create -f /root/nginx-ds.yaml [root@hdss7-22 conf]# kubectl get pods NAME READY STATUS RESTARTS AGE nginx-ds-j777c 1/1 Running 0 8s nginx-ds-nwsd6 1/1 Running 0 8s 7.2.2 在另一台node节点上检查 kubectl get pods kubectl get pods -o wide curl 172.7.22.2 7.2.3 查看kubernetes是否搭建好 [root@hdss7-22 conf]# kubectl get cs NAME STATUS MESSAGE ERROR etcd-0 Healthy {\"health\": \"true\"} etcd-2 Healthy {\"health\": \"true\"} etcd-1 Healthy {\"health\": \"true\"} controller-manager Healthy ok scheduler Healthy ok [root@hdss7-21 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION hdss7-21.host.com Ready master,node 6d1h v1.15.5 hdss7-22.host.com Ready \u003cnone\u003e 6d1h v1.15.5 [root@hdss7-22 ~]# kubectl get pods NAME READY STATUS RESTARTS AGE nginx-ds-j777c 1/1 Running 0 6m45s nginx-ds-nwsd6 1/1 Running 0 6m45s ","date":"2020-10-01","objectID":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/:7:2","tags":["K8S","转载"],"title":"02_K8S_二进制部署实践","uri":"/02_k8s%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/"},{"categories":["spring"],"content":"SpringMVC ","date":"2016-10-27","objectID":"/01_springmvc_flow/:0:0","tags":["springmvc"],"title":"01_springmvc_flow","uri":"/01_springmvc_flow/"},{"categories":["spring"],"content":"SpringMVC流程图 ","date":"2016-10-27","objectID":"/01_springmvc_flow/:1:0","tags":["springmvc"],"title":"01_springmvc_flow","uri":"/01_springmvc_flow/"},{"categories":["spring"],"content":"SpringMVC 九大组件 翻看SpringMVC源码会发现 DispatcherServlet 用于处理上传请求。处理方法是将普通的request包装成MultipartHttpServletRequest，后者可以直接调用getFile方法获取File，如果上传多个文件，还可以调用getFileMap得到FileName-\u003eFile结构的Map。此组件中一共有三个方法，作用分别是判断是不是上传请求，将request包装成MultipartHttpServletRequest、处理完后清理上传过程中产生的临时资源。 解析视图需要两个参数：一是视图名，另一个是Locale。视图名是处理器返回的，Locale是从哪里来的？这就是LocaleResolver要做的事情。LocaleResolver用于从request解析出Locale，Locale就是zh-cn之类，表示一个区域，有了这个就可以对不同区域的用户显示不同的结果。SpringMVC主要有两个地方用到了Locale：一是ViewResolver视图解析的时候；二是用到国际化资源或者主题的时候。 用于解析主题。SpringMVC中一个主题对应一个properties文件，里面存放着跟当前主题相关的所有资源、如图片、css样式等。SpringMVC的主题也支持国际化，同一个主题不同区域也可以显示不同的风格。SpringMVC中跟主题相关的类有 ThemeResolver、ThemeSource和Theme。主题是通过一系列资源来具体体现的，要得到一个主题的资源，首先要得到资源的名称，这是ThemeResolver的工作。然后通过主题名称找到对应的主题（可以理解为一个配置）文件，这是ThemeSource的工作。最后从主题中获取资源就可以了。 是用来查找Handler的。在SpringMVC中会有很多请求，每个请求都需要一个Handler处理，具体接收到一个请求之后使用哪个Handler进行处理呢？这就是HandlerMapping需要做的事。 从名字上看，它就是一个适配器。因为SpringMVC中的Handler可以是任意的形式，只要能处理请求就ok，但是Servlet需要的处理方法的结构却是固定的，都是以request和response为参数的方法。如何让固定的Servlet处理方法调用灵活的Handler来进行处理呢？这就是HandlerAdapter要做的事情。 小结：Handler是用来干活的工具；HandlerMapping用于根据需要干的活找到相应的工具；HandlerAdapter是使用工具干活的人。 其它组件都是用来干活的。在干活的过程中难免会出现问题，出问题后怎么办呢？这就需要有一个专门的角色对异常情况进行处理，在SpringMVC中就是HandlerExceptionResolver。具体来说，此组件的作用是根据异常设置ModelAndView，之后再交给render方法进行渲染。 ViewName是根据ViewName查找View，但有的Handler处理完后并没有设置View也没有设置ViewName，这时就需要从request获取ViewName了，如何从request中获取ViewName就是RequestToViewNameTranslator要做的事情了。RequestToViewNameTranslator在Spring MVC容器里只可以配置一个，所以所有request到ViewName的转换规则都要在一个Translator里面全部实现。 ViewResolver用来将String类型的视图名和Locale解析为View类型的视图。View是用来渲染页面的，也就是将程序返回的参数填入模板里，生成html（也可能是其它类型）文件。这里就有两个关键问题：使用哪个模板？用什么技术（规则）填入参数？这其实是ViewResolver主要要做的工作，ViewResolver需要找到渲染所用的模板和所用的技术（也就是视图的类型）进行渲染，具体的渲染过程则交由不同的视图自己完成。 用来管理FlashMap的，FlashMap主要用在redirect中传递参数。 ","date":"2016-10-27","objectID":"/01_springmvc_flow/:2:0","tags":["springmvc"],"title":"01_springmvc_flow","uri":"/01_springmvc_flow/"},{"categories":["spring"],"content":"DispatcherServlet Init dispatcherServlet是springmvc的核心 ","date":"2016-10-28","objectID":"/02_springmvc_init/:0:0","tags":["springmvc"],"title":"02_springmvc_init","uri":"/02_springmvc_init/"},{"categories":["spring"],"content":"servlet的生命周期 ==servlet==的三个重要方法init service destroy 1.被创建：执行init方法，只执行一次 　1.1 Servlet什么时候被创建？ 　1.2 默认情况下，第一次被访问时，Servlet被创建，然后执行init方法； 　1.3 可以配置执行Servlet的创建时机； 2.提供服务：执行service方法，执行多次 3.被销毁：当Servlet服务器正常关闭时，执行destroy方法，只执行一次 ","date":"2016-10-28","objectID":"/02_springmvc_init/:1:0","tags":["springmvc"],"title":"02_springmvc_init","uri":"/02_springmvc_init/"},{"categories":["spring"],"content":"init dispatcherServlet的init做了什么？ 最重要的方法：initServletBean() 到此SpringMVC的初始化基本结束。 总结： 完成上下文springmvc的上下文配置 初始化九大组件的策略配置 ","date":"2016-10-28","objectID":"/02_springmvc_init/:2:0","tags":["springmvc"],"title":"02_springmvc_init","uri":"/02_springmvc_init/"},{"categories":["spring"],"content":"service service是servlet的业务处理核心，此处又做了些什么？ DispatcherServlet的service主要业务处理方法在doDispatch中 ","date":"2016-10-28","objectID":"/02_springmvc_init/:3:0","tags":["springmvc"],"title":"02_springmvc_init","uri":"/02_springmvc_init/"},{"categories":["spring"],"content":"HandlerMapping HandlerMapping接口负责根据request请求找到对应的Handler处理器及Interceptor拦截器，并将它们封装在HandlerExecutionChain对象内，返回给中央调度器。 HandlerMapping接口只有一个方法： @Nullable HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception; 这里我们主要讲清楚两个问题： HandlerMapping初始化 HandlerMapping的唯一方法getHandler ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:0:0","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"HandlerMapping初始化 我们在第02_DispatcherServlet里已经看到过了Springmvc初始化handlerMapping策略的方法：initHandlerMappings 此处可以看到将HandlerMapping的实现类封装到了handlerMappings属性中。 那HandlerMapping的实现类是在什么时候实例化的，并且里面有哪些东西呢？带着这个疑问我们往下走。 这里我们以RequestMappingHandlerMapping为例： 在非SpringBoot的环境下，我们以前写spring的启动配置dispatchServlet.xml的时候总会加一行 \u003cmvc:annotation-driven/\u003e 这个配置会为我们初始化三个类 RequestMappingHandlerMapping RequestMappingHandlerAdapter ExceptionHandlerExceptionResolver 但是在SpringBoot环境下，配置都是自动化添加的，那我们看一下spring-boot-autoconfigure的spring.factories，再搜索一下web。我们能在其中找到下面这个配置类： org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration 这个类中有一个静态类EnableWebMvcConfiguration的目录结构如下： 在其中，我们可以看到有一个方法createRequestMappingHandlerMapping。 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:1:0","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"InitializingBean接口 在上面的RequestMappingHandlerMapping类图中，我们看到该类实现了InitializingBean接口，接口方法实现如下： 方法中实例化了一个BuilderConfiguration对象，并为该对象设置了一些路径抓取器，路径方法匹配器等。最后还需要调用父类的方法 该方法比较重要，看名字可以猜测是初始化HandlerMethods用的。方法实现如下： 第一步是遍历AplicationContext中的所有Bean，只要不是以SCOPED_TARGET_NAME_PREFIX（private static final String SCOPED_TARGET_NAME_PREFIX = “scopedTarget.\";）开头就调用processCandidatebean方法，方法如下： 拿到Bean的类型，调用isHandler(beanType)方法，该方法如下： 看到两个非常熟悉的注解@Controller和@RequestMapping。 如果该Bean标注了以上两个注解，那么调用detectHandlerMethos(beanName)，方法如下： 看方法描述可知，该方法在指定的bean中寻找handler methods。 我们先来看看该类中第一个重要的方法getMappingForMethod(method, userType)，方法如下： 通过方法或者通过类级别标注的RequestMapping注解创建RequestMappingInfo， 这里可以看出RequestMappingInfo主要存放的就是RequestMapping注解标注的方法的相关信息请求信息。到这里RequestMappingInfo已经构造完成。然后我们回到之前的方法，在遍历完标注了@Controller或者@RequestMapping的类的方法并且生成了对应的RequestMappingInfo之后调用registerHandlerMethod 至此，Controller中的HandlerMethods方法遍历查找并且注册到了RequestMapptinHandlerMapping中的mappingRegistry属性中。第一步结束。 我们再回到初始化之前，看 initHandlerMethods 接下来又做了什么? 翻看第6张图，得到接下来调用 handlerMethodsInitialized 方法： 从该方法看到handlerMethods初始化结束之后并没有做其他特别的事，但是有一行注释，我们发现。handlerMethods包括了两部分：springmvc自动监测到的和用户显示通过registerMapping（）方法添加的。 到这里为止，InitializingBean方法执行结束。 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:1:1","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"ApplicationContextAware接口 回到之前看的类结构图，得知该还继承了ApplicationObjectSupport类，而该类又实现了ApplicationContextAware接口。那我们再来看看该接口方法做了什么。 从该方法得知：该类对子类暴露了一个方法initApplicationContext，我们从RequestMappingHandlerMapping的父类AbstractHandlerMapping中看到以下实现： 我们看到这里内部执行了三个方法， extendInterceptors(this.interceptors) 该方法体内部为空，给子类使用 detectMappedInterceptors(this.adaptedInterceptors) 从所有Bean对象中找出MappedInterceptor类的的Bean，添加到this.this.adaptedInterceptors中。 initInterceptors() 将默认interceptors拦截器放入this.adaptedInterceptors中， 比如SpringBoot配置类EnableWebMvcConfiguration默认添加了两个拦截器ConversionServiceExposingInterceptor ResourceUrlProviderExposingInterceptor @Bean @Primary @Override public RequestMappingHandlerMapping requestMappingHandlerMapping( @Qualifier(\"mvcContentNegotiationManager\") ContentNegotiationManager contentNegotiationManager, @Qualifier(\"mvcConversionService\") FormattingConversionService conversionService, @Qualifier(\"mvcResourceUrlProvider\") ResourceUrlProvider resourceUrlProvider) { // Must be @Primary for MvcUriComponentsBuilder to work return super.requestMappingHandlerMapping(contentNegotiationManager, conversionService, resourceUrlProvider); } ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:1:2","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"HandlerInterceptor HandlerInterceptor接口主要有三个方法，三个方法会在dispatcherServlet执行过程中调用 preHandle：执行HandlerAdaptor的handle方法前。 default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { return true; } preHandle：执行HandlerAdaptor的handle方法后。 default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception { } afterCompletion：doDispatch方法执行完成前，即使抛出异常也会执行。 default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception { } 至此，ApplicationContextAware接口方法initApplicationContext执行结束 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:1:3","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"getHandler方法 HandlerExecutionChain getHandler(HttpServletRequest request) 我们来看第一个方法getHandlerInternal(request) 通过UrlPathHelper从request获取请求的path，然后根据path调用lookupHandlerMethod()方法获取处理这个request的HandlerMethod。 lookupHandlerMethod方法作用：查找当前请求的最佳匹配处理程序方法，如果找到多个匹配项，则选择最佳匹配项。这个方法的作用也比较明确，就不多说了。 回到之前，找到HandlerMethod，如果没有找到，返回默认的Handler。接下来是最核心的方法getHandlerExecutionChain(handler, request) 从此方法可以看出通过HandlerMethod new了一个HandlerExecutionChain对象。然后将属性adaptedInterceptors中的HandlerInterceptor添加到HandlerExecutionChain中，形成了调用执行链。 其中一个包括includePatterns和excludePatterns字符串集合并带有MappedInterceptor的类。 很明显，就是对于某些地址做特殊包括和排除的拦截器。 接下来，判断请求或者Handler是否是CROS请求，如果是，则添加 chain.addInterceptor(0, new CorsInterceptor(config)); 到此，getHandler执行结束。 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:2:0","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"使用 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:3:0","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"基础用法 实现HandlerInterceptor接口 package com.example.springmvcexample.handlerMapping; import lombok.extern.slf4j.Slf4j; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @Slf4j public class LogHandlerInterceptor implements HandlerInterceptor { public LogHandlerInterceptor() { log.info(\"LogHandlerInterceptor 构造方法被调用\"); } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { log.info(\"preHandle hanlder = {}\", handler); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { log.info(\"postHandle hanlder = {}, modelAndView = {}\", handler, modelAndView); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { log.info(\"postHandle hanlder = {}, Exception = {}\", handler, ex); } } 注意： 实现HandlerInterceptor接口的实现类使用@Component注解之后，仍然无法使用，因为该实例没有被放入AbstractHandlerMapping的adaptedInterceptors属性中。 继承WebMvcConfigurationSupport重写addInterceptors方法，将自定义的拦截器放入adaptedInterceptors中。 package com.example.springmvcexample.handlerMapping; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; import org.springframework.web.servlet.handler.MappedInterceptor; @Configuration public class WebMvcConfig extends WebMvcConfigurationSupport { @Override protected void addInterceptors(InterceptorRegistry registry) { super.addInterceptors(registry); // 第一种直接添加自定义的拦截器 // registry.addInterceptor(new LogHandlerInterceptor()); // 如果需要对指定url的请求调用拦截器，使用MappedInterceptor String[] includes = new String[]{\"/hello/{name}\"}; String[] excludes = new String[]{\"/echo/{name}\"}; registry.addInterceptor(new MappedInterceptor(includes, excludes, new LogHandlerInterceptor())); } } 如果是异步请求使用WebRequestInterceptor，这里不作具体描述。 ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:3:1","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"高级用法 自定义HandlerMapping 参考spring boot actuator 的 WebMvcEndpointHandlerMapping ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:3:2","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"总结 RequestMappingHandlerMapping初始化过程中会遍历所有的Bean，找到注解了@Controller或者@RequestMapping的类，通过反射找到所有的注解了@RequestMapping的方法，将其信息封装到一个RequestMapingInfo类对象中；最后将Handler（可以理解为Controller）、Method（注解标记的方法）、RequestMappingInfo三者注册到mappingRegistry的registry属性中。 执行doDispatch方法内部调用getHandler方法将HandlerInterceptor实现类封装得到HandlerExecutionChain对象。 得到HandlerExecutionChain对象之后调用HandlerInterceptor的preHandle方法 调用HandlerAdapter的handle方法后调用HandlerInterceptor的postHandle方法 在doDispatch方法调用结束前调用HandlerInterceptor的afterCompletion方法（异常处理之后，preHandle返回false也会执行） ","date":"2016-10-29","objectID":"/03_springmvc_handlermapping/:4:0","tags":["springmvc"],"title":"03_springmvc_handlermapping","uri":"/03_springmvc_handlermapping/"},{"categories":["spring"],"content":"HandlerAdapter HandlerAdapter是处理器适配器，Spring MVC通过HandlerAdapter来实际调用处理函数。它是SpringMvc处理流程的第二步,当HandlerMapping获取了定位请求处理器Handler，DispatcherServlet会将得到的Handler告知HandlerAdapter，HandlerAdapter再根据请求去定位请求的具体处理方法是哪一个。 HandlerAdapter定义了如何处理请求的策略，通过请求url、请求Method和处理器的requestMapping定义，最终确定使用处理类的哪个方法来处理请求，并检查处理类相应处理方法的参数以及相关的Annotation配置，确定如何转换需要的参数传入调用方法，并最终调用返回ModelAndView。 DispatcherServlet中根据HandlerMapping找到对应的handler method后，首先检查当前工程中注册的所有可用的handlerAdapter，根据handlerAdapter中的supports方法找到可以使用的handlerAdapter。 通过调用handlerAdapter中的handler方法来处理及准备handler method的参数及annotation(这就是spring mvc如何将request中的参数变成handle method中的输入参数的地方)，最终调用实际的handler method。 handlerAdapter这个类的作用就是接过handlermapping解析请求得到的handler对象。在更精确的定位到能够执行请求的方法。 initStrategies调用initHandlerAdapters ❶从Spring的上下文环境中获取实现了HandlerAdapter接口的实现类，默认会有以下实现类： RequestMappingHandlerAdapter HandlerFunctionAdapter HttpRequestHandlerAdapter SimpleControllerHandlerAdapter ❷对❶中查找到的实现类排序 ❸如果配置了detectAllHandlerAdapters属性为false，则从Spring上下文中获取一个beanName = handlerAdapter的实例 ❹如果前几步都没有获取到HandlerAdapter的实现类，则从dispatcherServlet.properties中获取默认的实现类。 org.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter,\\ org.springframework.web.servlet.function.support.HandlerFunctionAdapter RequestMappingHandlerAdapterUML类图，在没有自定义特殊情况下，该类便是HandlerAdapter的主要实现类。以下我们便以该类来讲解。 ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:0:0","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"InitializationBean 由以上类图可知：RequestMappingHandlerAdapter实现了InitializationBean接口，所以我们看一眼该接口方法做了什么？ afterPropertiesSet ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:1:0","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"❶ InitControllerAdviceCache 遍历Spring上下文实例，找出@ControllerAdvice、@ModelAttribute、@InitBinder和实现了RequestBodyAdvice或者ResponseBodyAdvice相关的处理方法，并缓存起来。具体如下： 从Spring上下文找到@ControllerAdvice注解的类 遍历1.中找到的标记了@ControllerAdvice的类中找到注解了@ModelAttribute的方法 遍历1.中找到的标记了@ControllerAdvice的类中找到注解了@InitBinder的方法 遍历1.中找到的标记了@ControllerAdvice的类中找到实现了RequestBodyAdvice和ResponseBodyAdvice的实现 ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:1:1","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"❷ 参数解析器 解析特定注解的参数 参数校验 获取默认的参数解析器，针对各种类型参数具体解析器如下： 由该方法可知，参数解析器包含了4大块：基于注解的，基于类型的，自定义的，其他 所以接口都实现了HandlerMethodArgumentResolver接口。该接口有两个方法，一个判断是否支持该类型参数，一个用于解析参数。 RequestParamMethodArgumentResolver 主要用来解析@RequestParam注解的参数 RequestParamMapMethodArgumentResolver 用来解析@RequestParam注解并参数类型为Map的参数，并且requestParam.name为空 @Override public boolean supportsParameter(MethodParameter parameter) { RequestParam requestParam = parameter.getParameterAnnotation(RequestParam.class); return (requestParam != null \u0026\u0026 Map.class.isAssignableFrom(parameter.getParameterType()) \u0026\u0026 !StringUtils.hasText(requestParam.name())); PathVariableMethodArgumentResolver 用来解析@PathVariable注解的参数；参数类型是Map，并且pathVariable.value()存在的参数 @Override public boolean supportsParameter(MethodParameter parameter) { if (!parameter.hasParameterAnnotation(PathVariable.class)) { return false; } if (Map.class.isAssignableFrom(parameter.nestedIfOptional().getNestedParameterType())) { PathVariable pathVariable = parameter.getParameterAnnotation(PathVariable.class); return (pathVariable != null \u0026\u0026 StringUtils.hasText(pathVariable.value())); } return true; } PathVariableMapMethodArgumentResolver 用来解析@PathVariable注解的参数类型是Map，并且pathVariable.value()不存在的参数 @Override public boolean supportsParameter(MethodParameter parameter) { PathVariable ann = parameter.getParameterAnnotation(PathVariable.class); return (ann != null \u0026\u0026 Map.class.isAssignableFrom(parameter.getParameterType()) \u0026\u0026 !StringUtils.hasText(ann.value())); } MatrixVariableMethodArgumentResolver 用于解析@MatrixVariable注解的参数；*参数类型是Map，并且matrixVariable.name存在的参数，也能被解析，但是没有默认的数据绑定器，所以会报错。 @Override public boolean supportsParameter(MethodParameter parameter) { if (!parameter.hasParameterAnnotation(MatrixVariable.class)) { return false; } if (Map.class.isAssignableFrom(parameter.nestedIfOptional().getNestedParameterType())) { MatrixVariable matrixVariable = parameter.getParameterAnnotation(MatrixVariable.class); return (matrixVariable != null \u0026\u0026 StringUtils.hasText(matrixVariable.name())); } return true; } 示例 /** * 请求示例： GET http://localhost:8080/mv1/123;q=123/456;q=456 * 正常响应 */ @RequestMapping(\"/mv1/{x}/{y}\") public String matrixVairable1( @PathVariable String x, @PathVariable String y, @MatrixVariable(name = \"q\", pathVar = \"x\") int q1, @MatrixVariable(name = \"q\", pathVar = \"y\") int q2) { return String.format(\"x = %s, y = %s, q1 = %s, q2 = %s\", x, y, q1, q2); } /** * 请求示例： GET http://localhost:8080/mv2/q=123/q=456 * 正常响应 */ @RequestMapping(\"/mv2/{a}/{b}\") public String matrixVairable2( @MatrixVariable(name = \"q\", pathVar = \"a\") int q1, @MatrixVariable(name = \"q\", pathVar = \"b\") int q2) { return String.format(\"a = %s, b = %s\", q1, q2); } /** * 请求示例： GET http://localhost:8080/mv4/a=123/b=456; * 结果报错：Cannot convert value of type 'java.lang.String' to required type 'java.util.Map': no matching editors or conversion strategy found */ @RequestMapping(\"/mv4/{a}/{b}\") public String matrixVairable4( @MatrixVariable(name = \"a\", pathVar = \"a\") Map\u003cString, String\u003e m1, @MatrixVariable(name = \"b\", pathVar = \"b\") Map\u003cString, String\u003e m2) throws JsonProcessingException { ObjectMapper objectMapper = new ObjectMapper(); return String.format(\"a = %s, b = %s\", objectMapper.writeValueAsString(m1), objectMapper.writeValueAsString(m2)); } MatrixVariableMapMethodArgumentResolver 用于解析@MatrixVariable注解的参数类型是Map，并且matrixVariable.name不存在的参数 @Override public boolean supportsParameter(MethodParameter parameter) { MatrixVariable matrixVariable = parameter.getParameterAnnotation(MatrixVariable.class); return (matrixVariable != null \u0026\u0026 Map.class.isAssignableFrom(parameter.getParameterType()) \u0026\u0026 !StringUtils.hasText(matrixVariable.name())); } 示例 /** * 请求示例： GET http://localhost:8080/mv3/a1=123;a2=321/b1=456;b2=654 */ @RequestMapping(\"/mv3/{a}/{b}\") public String matrixVairable3( @MatrixVariable(pathVar = \"a\") Map\u003cString, String\u003e m1, @MatrixVariable(pathVar = \"b\") Map\u003cString, String\u003e m2) throws JsonProcessingException { ObjectMapper objectMapper = new ObjectMapper(); return Str","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:1:2","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"❸InitBinder参数解析器 调用@InitBinder注解的方法，解析被注解的方法的参数。 支持的参数解析器如下： /** * Return the list of argument resolvers to use for {@code @InitBinder} * methods including built-in and custom resolvers. */ private List\u003cHandlerMethodArgumentResolver\u003e getDefaultInitBinderArgumentResolvers() { List\u003cHandlerMethodArgumentResolver\u003e resolvers = new ArrayList\u003c\u003e(); // Annotation-based argument resolution resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); resolvers.add(new RequestParamMapMethodArgumentResolver()); resolvers.add(new PathVariableMethodArgumentResolver()); resolvers.add(new PathVariableMapMethodArgumentResolver()); resolvers.add(new MatrixVariableMethodArgumentResolver()); resolvers.add(new MatrixVariableMapMethodArgumentResolver()); resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new SessionAttributeMethodArgumentResolver()); resolvers.add(new RequestAttributeMethodArgumentResolver()); // Type-based argument resolution resolvers.add(new ServletRequestMethodArgumentResolver()); resolvers.add(new ServletResponseMethodArgumentResolver()); // Custom arguments if (getCustomArgumentResolvers() != null) { resolvers.addAll(getCustomArgumentResolvers()); } // Catch-all resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); return resolvers; } 调用流程： Controller标注的@RequestMapping方法的参数解析时，比如：RequestParamMethodArgumentResolver解析器。有如下代码： ...省略 if (binderFactory != null) { // 创建WebDataBinder对象，其中调用@InitBinder注解的方法 WebDataBinder binder = binderFactory.createBinder(webRequest, null, namedValueInfo.name); try { arg = binder.convertIfNecessary(arg, parameter.getParameterType(), parameter); } catch (ConversionNotSupportedException ex) { throw new MethodArgumentConversionNotSupportedException(arg, ex.getRequiredType(), namedValueInfo.name, parameter, ex.getCause()); } catch (TypeMismatchException ex) { throw new MethodArgumentTypeMismatchException(arg, ex.getRequiredType(), namedValueInfo.name, parameter, ex.getCause()); } } ...省略 public final WebDataBinder createBinder( NativeWebRequest webRequest, @Nullable Object target, String objectName) throws Exception { WebDataBinder dataBinder = createBinderInstance(target, objectName, webRequest); if (this.initializer != null) { // 为initbinder方法添加消息转换大，属性编辑器等 this.initializer.initBinder(dataBinder, webRequest); } // 调用@InitBinder方法 initBinder(dataBinder, webRequest); return dataBinder; } 调用@ControllerAdvice中@InitBinder的全局方法和@Controller中的单属于每个controller的@InitBinder方法 public void initBinder(WebDataBinder dataBinder, NativeWebRequest request) throws Exception { for (InvocableHandlerMethod binderMethod : this.binderMethods) { if (isBinderMethodApplicable(binderMethod, dataBinder)) { // 调用@initBinder注解的方法 Object returnValue = binderMethod.invokeForRequest(request, null, dataBinder); if (returnValue != null) { throw new IllegalStateException( \"@InitBinder methods must not return a value (should be void): \" + binderMethod); } } } } 调用参数解析器解析initBinder参数 protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { ... 省略 // 此处resolvers便是afterPropertiesSet中调用getDefaultInitBinderArgumentResolvers() if (!this.resolvers.supportsParameter(parameter)) { throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\")); } try { args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); } ... 省略 } ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:1:3","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"❹返回值解析器 处理返回值 源码位置： public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { // ①调用handle，Controller方法的处理函数得到返回值 Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) { if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) { disableContentCachingIfNecessary(webRequest); mavContainer.setRequestHandled(true); return; } } else if (StringUtils.hasText(getResponseStatusReason())) { mavContainer.setRequestHandled(true); return; } mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, \"No return value handlers\"); try { // ②处理返回值 this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); } catch (Exception ex) { if (logger.isTraceEnabled()) { logger.trace(formatErrorForReturnValue(returnValue), ex); } throw ex; } } ①处调用请求的处理，②处调用返回值处理逻辑。 返回值处理逻辑如下： /** * Iterate over registered {@link HandlerMethodReturnValueHandler HandlerMethodReturnValueHandlers} and invoke the one that supports it. * @throws IllegalStateException if no suitable {@link HandlerMethodReturnValueHandler} is found. */ @Override public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception { // 获取处理返回值的解析器 HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType); if (handler == null) { throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName()); } // 根据返回的对应解析器处理返回值 handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest); } ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:1:4","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"handle流程 handle方法是HandleAdapter的核心方法，Controller中业务的处理逻辑也是在此方法中被调用 RequestMappingHandlerAdapter中的handle方法如下： /** * This implementation expects the handler to be an {@link HandlerMethod}. */ @Override @Nullable public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { return handleInternal(request, response, (HandlerMethod) handler); } ![image-20200725153200873](/Users/Adam.Jin/Library/Mobile Documents/com~apple~CloudDocs/笔记/技术/Java/springmvc/04_HandlerAdapter.assets/image-20200725153200873.png) invokeHandlerMethod方法： ❶、获取DataBinderFactory代码如下： ❷、获取ModelFactory的逻辑与DataBinderFacotory差不多 ❼、参数名解析参考https://blog.csdn.net/qq271859852/article/details/84963672 ❽、填充model数据，包括SessionAtrribute中的数据。 接着调用invokeAndHandle方法 ","date":"2016-10-30","objectID":"/04_springmvc_handleradapter/:2:0","tags":["springmvc"],"title":"04_springmvc_handleradapter","uri":"/04_springmvc_handleradapter/"},{"categories":["spring"],"content":"HandlerExceptionResolver Spring的处理器异常解析器HandlerExceptionResolver接口的实现负责处理各类控制器执行过程中出现的异常 public interface HandlerExceptionResolver { @Nullable ModelAndView resolveException( HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex); } ","date":"2016-11-01","objectID":"/05_springmvc_handlerexceptionresolver/:0:0","tags":["springmvc"],"title":"05_springmvc_handlerExceptionResolver","uri":"/05_springmvc_handlerexceptionresolver/"},{"categories":["spring"],"content":"初始化 初始化过程比较简单，在DispatcherServlet类initStrategies方法中调用initHandlerExceptionResolvers获取所有实现了HandlerExceptionResolver接口的实例 /** * Initialize the HandlerExceptionResolver used by this class. * \u003cp\u003eIf no bean is defined with the given name in the BeanFactory for this namespace, * we default to no exception resolver. */ private void initHandlerExceptionResolvers(ApplicationContext context) { this.handlerExceptionResolvers = null; if (this.detectAllHandlerExceptionResolvers) { // Find all HandlerExceptionResolvers in the ApplicationContext, including ancestor contexts. // 找到所有实现了HandlerExceptionResolver接口 Map\u003cString, HandlerExceptionResolver\u003e matchingBeans = BeanFactoryUtils .beansOfTypeIncludingAncestors(context, HandlerExceptionResolver.class, true, false); if (!matchingBeans.isEmpty()) { this.handlerExceptionResolvers = new ArrayList\u003c\u003e(matchingBeans.values()); // We keep HandlerExceptionResolvers in sorted order. AnnotationAwareOrderComparator.sort(this.handlerExceptionResolvers); } } else { try { HandlerExceptionResolver her = context.getBean(HANDLER_EXCEPTION_RESOLVER_BEAN_NAME, HandlerExceptionResolver.class); this.handlerExceptionResolvers = Collections.singletonList(her); } catch (NoSuchBeanDefinitionException ex) { // Ignore, no HandlerExceptionResolver is fine too. } } // Ensure we have at least some HandlerExceptionResolvers, by registering // default HandlerExceptionResolvers if no other resolvers are found. // 获取默认的异常解析器 if (this.handlerExceptionResolvers == null) { this.handlerExceptionResolvers = getDefaultStrategies(context, HandlerExceptionResolver.class); if (logger.isTraceEnabled()) { logger.trace(\"No HandlerExceptionResolvers declared in servlet '\" + getServletName() + \"': using default strategies from DispatcherServlet.properties\"); } } } ","date":"2016-11-01","objectID":"/05_springmvc_handlerexceptionresolver/:1:0","tags":["springmvc"],"title":"05_springmvc_handlerExceptionResolver","uri":"/05_springmvc_handlerexceptionresolver/"},{"categories":["spring"],"content":"处理逻辑 在处理请求过程中，当发生了异常，被try…catch抓到之后，赋值给了dispatchException变量，然后在processDispatchResult方法中，判断exception是否为空，非空即表示存在异常，调用异常处理解析器（方法：processHandlerException）处理异常，返回ModelAndView private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception { boolean errorView = false; if (exception != null) { if (exception instanceof ModelAndViewDefiningException) { logger.debug(\"ModelAndViewDefiningException encountered\", exception); mv = ((ModelAndViewDefiningException) exception).getModelAndView(); } else { Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); // 处理异常 mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); } } // Did the handler return a view to render? if (mv != null \u0026\u0026 !mv.wasCleared()) { render(mv, request, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } ...省略 } 处理异常 protected ModelAndView processHandlerException(HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex) throws Exception { ... 省略 // Check registered HandlerExceptionResolvers... ModelAndView exMv = null; if (this.handlerExceptionResolvers != null) { for (HandlerExceptionResolver resolver : this.handlerExceptionResolvers) { // 调用异常处理解析器处理异常 exMv = resolver.resolveException(request, response, handler, ex); if (exMv != null) { break; } } } ...省略 throw ex; } ","date":"2016-11-01","objectID":"/05_springmvc_handlerexceptionresolver/:2:0","tags":["springmvc"],"title":"05_springmvc_handlerExceptionResolver","uri":"/05_springmvc_handlerexceptionresolver/"},{"categories":["spring"],"content":"ExceptionHandlerMethodResolver 异常解析器中默认最常用的，也是工作中使用最多的，就是该类。主要处理@ExceptionHandler注解 该类继承和实现的接口如下图： 由上图可知，该类主要实现了HandlerExeptionResolver用于解析异常，并且实现了@InitializationBean接口。 @InitializationBean @Override public void afterPropertiesSet() { // Do this first, it may add ResponseBodyAdvice beans // ① initExceptionHandlerAdviceCache(); // ② if (this.argumentResolvers == null) { List\u003cHandlerMethodArgumentResolver\u003e resolvers = getDefaultArgumentResolvers(); this.argumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); } // ③ if (this.returnValueHandlers == null) { List\u003cHandlerMethodReturnValueHandler\u003e handlers = getDefaultReturnValueHandlers(); this.returnValueHandlers = new HandlerMethodReturnValueHandlerComposite().addHandlers(handlers); } } ① 、遍历所有标注了ControllerAdvice的类，并从标注了该注解的类下找到所有标注了@ExceptionHandler的方法。具体代码如下： private void initExceptionHandlerAdviceCache() { ... 省略 // 遍历Spring上下文，找出所有@ControllerAdvice的Bean List\u003cControllerAdviceBean\u003e adviceBeans = ControllerAdviceBean.findAnnotatedBeans(getApplicationContext()); for (ControllerAdviceBean adviceBean : adviceBeans) { Class\u003c?\u003e beanType = adviceBean.getBeanType(); if (beanType == null) { throw new IllegalStateException(\"Unresolvable type for ControllerAdviceBean: \" + adviceBean); } // 循环所有@ControllerAdvice的Bean，构造ExceptionHandlerMethodResolver实例用于缓存处理异常的方法 ExceptionHandlerMethodResolver resolver = new ExceptionHandlerMethodResolver(beanType); // 如果该@ControllerAdvice中没有@ExceptionHandler，则丢弃刚new的实例 if (resolver.hasExceptionMappings()) { this.exceptionHandlerAdviceCache.put(adviceBean, resolver); } // 如果标注了@ControllerAdvice的类实现了ResponseBodyAdvice，放到responseBodyAdvice属性中 if (ResponseBodyAdvice.class.isAssignableFrom(beanType)) { this.responseBodyAdvice.add(adviceBean); } } ... 省略 } ②、获取异常处理解析器中，用于异常处理方法的参数解析器 ③、获取异常处理解析器中，用于异常处理方法的返回值解析器 接下来的流程和HandlerAdapter的处理逻辑差不多 @Override @Nullable protected ModelAndView doResolveHandlerMethodException(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerMethod handlerMethod, Exception exception) { // 获取异常处理方法 ServletInvocableHandlerMethod exceptionHandlerMethod = getExceptionHandlerMethod(handlerMethod, exception); if (exceptionHandlerMethod == null) { return null; } // 设置异常处理方法的参数解析器 if (this.argumentResolvers != null) { exceptionHandlerMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); } // 设置异常处理方法的返回值解析器 if (this.returnValueHandlers != null) { exceptionHandlerMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); } ServletWebRequest webRequest = new ServletWebRequest(request, response); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); try { if (logger.isDebugEnabled()) { logger.debug(\"Using @ExceptionHandler \" + exceptionHandlerMethod); } Throwable cause = exception.getCause(); if (cause != null) { // Expose cause as provided argument as well // 调用异常解析方法 exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, exception, cause, handlerMethod); } else { // Otherwise, just the given exception as-is // 调用异常解析方法 exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, exception, handlerMethod); } } catch (Throwable invocationEx) { // Any other than the original exception (or its cause) is unintended here, // probably an accident (e.g. failed assertion or the like). if (invocationEx != exception \u0026\u0026 invocationEx != exception.getCause() \u0026\u0026 logger.isWarnEnabled()) { logger.warn(\"Failure in @ExceptionHandler \" + exceptionHandlerMethod, invocationEx); } // Continue with default processing of the original exception... return null; } if (mavContainer.isRequestHandled()) { return new ModelAndView(); } else { ModelMap model = mavContainer.getModel(); HttpStatus status = mavContainer.getStatus(); ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, status); mav.setViewName(mavContainer.getViewName()); if (!mavContainer.isViewReference()) { mav.setView((View) mavContainer.getView()); } if (model instanceof RedirectAttributes) {","date":"2016-11-01","objectID":"/05_springmvc_handlerexceptionresolver/:2:1","tags":["springmvc"],"title":"05_springmvc_handlerExceptionResolver","uri":"/05_springmvc_handlerexceptionresolver/"},{"categories":["spring"],"content":"参数校验器 Spring MVC中的参数校验器并没有自己大量从新开发，而是使用了Hibernate-Validator，而Hibernate-Validator实现了JSR-303的所有功能。在SpringMVC中有两个地方可以于用参数校验。 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:0:0","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"1、Bean Validator 此处的Bean Validator指JSR-303（JSR是Java Specification Requests的缩写，意思是Java 规范提案，其中303号内容指提供一套基于注解的校验规范[This JSR will define a meta-data model and API for JavaBeanTM validation based on annotations, with overrides and extended meta-data through the use of XML validation descriptors.]）。Hibernate Validator是它最出名的实现，也是目前世界上使用最广的校验器实现。Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint 的实现，除此之外还有一些附加的 constraint。 Annotation 注解说明 备注 DecimalMax 元素必须是一个数字，其值必须小于或等于指定的最大值 DecimalMin 元素必须是一个数字，其值必须大于或等于指定的最小值 Pattern 必须与指定的正则表达式匹配 Email 检查给定的字符序列（例如字符串）是否是格式正确的电子邮件地址 Max 元素必须是一个数字，其值必须小于或等于指定的最大值 Min 元素必须是一个数字，其值必须大于或等于指定的最小值 AssertFalse 元素的值必须为false AssertTrue 元素的值必须为true Digits 元素必须是可接受范围内的数字 NegativeOrZero 元素必须为严格的负数（即0视为无效值） NotBlank 删除任何前导或尾随空格后，检查字符序列是否不为空 NotEmpty 元素必须不为null且不为empty NotNull 元素必须不为null Null 元素必须为null PositiveOrZero 元素必须为正数或0 Positive 元素必须为严格的正数（即0视为无效值） Size 元素大小必须在指定的边界（包括在内）之间。 Future 元素必须是将来的瞬间，日期或时间 FutureOrPresent 元素必须是当前或将来的瞬间，日期或时间 Past 元素必须是过去的瞬间，日期或时间 PastOrPresent 元素必须是过去或现在的瞬间，日期或时间 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:1:0","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"2、Hibernate Validator编程式校验 SpringBoot \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-validation\u003c/artifactId\u003e \u003c/dependency\u003e 直接导入 \u003cdependency\u003e \u003cgroupId\u003ejavax.validation\u003c/groupId\u003e \u003cartifactId\u003evalidation-api\u003c/artifactId\u003e \u003cversion\u003e2.0.0.Final\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.hibernate.validator\u003c/groupId\u003e \u003cartifactId\u003ehibernate-validator\u003c/artifactId\u003e \u003cversion\u003e6.1.5.Final\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e ","date":"2016-11-01","objectID":"/06_springmvc_validator/:2:0","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"2.1、普通对象校验 public class User { @NotNull private String name; @Min(value=\"1\") private String age; //... } ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); validator = factory.getValidator(); Set\u003cConstraintViolation\u003cCar\u003e\u003e constraintViolations = validator.validate( department ); assertEquals( 1, constraintViolations.size() ); assertEquals( \"must not be null\", constraintViolations.iterator().next().getMessage() ); Validation类是Bean Validation的入口点，buildDefaultValidatorFactory()方法基于默认的Bean Validation提供程序构建并返回ValidatorFactory实例。使用默认验证提供程序解析程序逻辑解析提供程序列表。代码上等同于Validation.byDefaultProvider().configure().buildValidatorFactory()。 之后调用该ValidatorFactory.getValidator()返回一个校验器实例，使用这个校验器的validate方法对目标对象的属性进行校验，返回一个ConstraintViolation集合。ConstraintViolation用于描述约束违规。 此对象公开约束违规上下文以及描述违规的消息。 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:2:1","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"2.2、分组校验 首先需要在constraint注解上指定groups属性，这个属性是一个class对象数组，再调用javax.validation.Validator接口的validate方法的时候将第二个参数groups传入class数组元素之一就可以针对这个这个group的校验规则生效。 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:2:2","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"HandlerMethodArgumentResolver 在04_HandlerAdaptor那一章节中我们已经讲过参数解析器了，在参数解析过程中，SpringMVC会对参数进行校验。 我们这里以RequestResponseBodyMethodProcessor来举例，该类实现了HandlerMethodArgumentResolver接口，用于处理@RequestBody标记的参数类型。 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:3:0","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"validateIfApplicable 该方法便是用于参数的校验，具体逻辑如下： ","date":"2016-11-01","objectID":"/06_springmvc_validator/:3:1","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["spring"],"content":"ValidationAutoConfiguration @RestController @Validated public class TestController { @RequestMapping(\"/test\") public String test(@RequestParam(\"age\") @Max(200) Integer age) { return String.format(\"age = %s\", age); } } spring驱动类：ValidationAutoConfiguration MethodValidationPostProcessor 校验器 https://blog.csdn.net/roberts939299/article/details/73730410 ","date":"2016-11-01","objectID":"/06_springmvc_validator/:4:0","tags":["springmvc"],"title":"06_springmvc_validator","uri":"/06_springmvc_validator/"},{"categories":["工具"],"content":"java解密代码如下： // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package com.test; import org.apache.commons.codec.digest.DigestUtils; import javax.crypto.Cipher; import javax.crypto.SecretKey; import javax.crypto.SecretKeyFactory; import javax.crypto.spec.DESKeySpec; import java.io.ByteArrayOutputStream; import java.io.DataOutputStream; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.security.SecureRandom; import java.util.Random; public class Test { // private static final String OO0O00OO00OOOOOO0000O0O000O0O0000OOOO00OO000OO0000OO000000O00O0O000OO00O0O000O00O0O00OOOOOO0OOO0 = \"DES\"; public static long number = 3680984568597093857L; private static int num = 8; public static void main(String[] args) throws Exception { String content = \"sdsfew1tf45r1g3\"; String s1 = encode(content); String s2 = decode(s1); System.out.println(s1); System.out.println(s2); } public static String decode(String data) throws IOException, Exception { if (data == null) { return null; } else { String rs = \"\"; if (!fff(data)) { byte[] buf = ggg(data); byte[] head = new byte[num]; System.arraycopy(buf, 0, head, 0, head.length); byte[] d = new byte[buf.length - head.length]; System.arraycopy(buf, head.length, d, 0, d.length); byte[] bt = jjj(d, kkk(head)); rs = new String(bt); } return rs; } } public static String encode(String content) throws Exception { byte[] head = aaa(num); byte[] d = bbb(content.getBytes(\"utf-8\"), head); byte[] result = new byte[head.length + d.length]; System.arraycopy(head, 0, result, 0, head.length); System.arraycopy(d, 0, result, head.length, d.length); String rs = ccc(result); return rs; } static byte[] aaa(int len) { byte[] data = new byte[len]; for(int i = 0; i \u003c len; ++i) { data[i] = (byte)(new Random()).nextInt(127); } return data; } public static byte[] bbb(byte[] data, byte[] head) throws Exception { SecureRandom sr = new SecureRandom(); DESKeySpec dks = new DESKeySpec(kkk(head)); SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(\"DES\"); SecretKey securekey = keyFactory.generateSecret(dks); Cipher cipher = Cipher.getInstance(\"DES\"); cipher.init(1, securekey, sr); return cipher.doFinal(data); } public static String ccc(byte[] byteData) throws UnsupportedEncodingException { return ddd(byteData, \"UTF-8\"); } public static String ddd(byte[] byteData, String encoding) throws UnsupportedEncodingException { if (byteData == null) { throw new IllegalArgumentException(\"byteData cannot be null\"); } else { return new String(eee(byteData), encoding); } } public static final byte[] eee(byte[] byteData) { if (byteData == null) { throw new IllegalArgumentException(\"byteData cannot be null\"); } else { byte[] byteDest = new byte[(byteData.length + 2) / 3 * 4]; int iSrcIdx = 0; int iDestIdx; for(iDestIdx = 0; iSrcIdx \u003c byteData.length - 2; iSrcIdx += 3) { byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx] \u003e\u003e\u003e 2 \u0026 63); byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx + 1] \u003e\u003e\u003e 4 \u0026 15 | byteData[iSrcIdx] \u003c\u003c 4 \u0026 63); byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx + 2] \u003e\u003e\u003e 6 \u0026 3 | byteData[iSrcIdx + 1] \u003c\u003c 2 \u0026 63); byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx + 2] \u0026 63); } if (iSrcIdx \u003c byteData.length) { byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx] \u003e\u003e\u003e 2 \u0026 63); if (iSrcIdx \u003c byteData.length - 1) { byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx + 1] \u003e\u003e\u003e 4 \u0026 15 | byteData[iSrcIdx] \u003c\u003c 4 \u0026 63); byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx + 1] \u003c\u003c 2 \u0026 63); } else { byteDest[iDestIdx++] = (byte)(byteData[iSrcIdx] \u003c\u003c 4 \u0026 63); } } for(iSrcIdx = 0; iSrcIdx \u003c iDestIdx; ++iSrcIdx) { if (byteDest[iSrcIdx] \u003c 26) { byteDest[iSrcIdx] = (byte)(byteDest[iSrcIdx] + 65); } else if (byteDest[iSrcIdx] \u003c 52) { byteDest[iSrcIdx] = (byte)(byteDest[iSrcIdx] + 97 - 26); } else if (byteDest[iSrcIdx] \u003c 62) { byteDest[iSrcIdx] = (byte)(byteDest[iSrcIdx] + 48 - 52); } else if (byteDest[iSrcIdx] \u003c 63) { byteDest[iSrcIdx] = 43; } else { byteDest[iSrcIdx] = 47; } } while(iSrcIdx \u003c","date":"2016-10-27","objectID":"/finalshell%E8%A7%A3%E5%AF%86/:0:0","tags":["finalshell"],"title":"01_finalshell密码破解","uri":"/finalshell%E8%A7%A3%E5%AF%86/"},{"categories":["工具"],"content":"navicat 解密 步骤如下 打开链接：https://tool.lu/coderunner/ 粘贴以下代码，修改倒数第二行 \u003c?php namespace FatSmallTools; class NavicatPassword { protected $version = 0; protected $aesKey = 'libcckeylibcckey'; protected $aesIv = 'libcciv libcciv '; protected $blowString = '3DC5CA39'; protected $blowKey = null; protected $blowIv = null; public function __construct($version = 12) { $this-\u003eversion = $version; $this-\u003eblowKey = sha1('3DC5CA39', true); $this-\u003eblowIv = hex2bin('d9c7c3c8870d64bd'); } public function encrypt($string) { $result = FALSE; switch ($this-\u003eversion) { case 11: $result = $this-\u003eencryptEleven($string); break; case 12: $result = $this-\u003eencryptTwelve($string); break; default: break; } return $result; } protected function encryptEleven($string) { $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ''; $currentVector = $this-\u003eblowIv; for ($i = 0; $i \u003c $round; $i++) { $temp = $this-\u003eencryptBlock($this-\u003exorBytes(substr($string, 8 * $i, 8), $currentVector)); $currentVector = $this-\u003exorBytes($currentVector, $temp); $result .= $temp; } if ($leftLength) { $currentVector = $this-\u003eencryptBlock($currentVector); $result .= $this-\u003exorBytes(substr($string, 8 * $i, $leftLength), $currentVector); } return strtoupper(bin2hex($result)); } protected function encryptBlock($block) { return openssl_encrypt($block, 'BF-ECB', $this-\u003eblowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); } protected function decryptBlock($block) { return openssl_decrypt($block, 'BF-ECB', $this-\u003eblowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); } protected function xorBytes($str1, $str2) { $result = ''; for ($i = 0; $i \u003c strlen($str1); $i++) { $result .= chr(ord($str1[$i]) ^ ord($str2[$i])); } return $result; } protected function encryptTwelve($string) { $result = openssl_encrypt($string, 'AES-128-CBC', $this-\u003eaesKey, OPENSSL_RAW_DATA, $this-\u003eaesIv); return strtoupper(bin2hex($result)); } public function decrypt($string) { $result = FALSE; switch ($this-\u003eversion) { case 11: $result = $this-\u003edecryptEleven($string); break; case 12: $result = $this-\u003edecryptTwelve($string); break; default: break; } return $result; } protected function decryptEleven($upperString) { $string = hex2bin(strtolower($upperString)); $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ''; $currentVector = $this-\u003eblowIv; for ($i = 0; $i \u003c $round; $i++) { $encryptedBlock = substr($string, 8 * $i, 8); $temp = $this-\u003exorBytes($this-\u003edecryptBlock($encryptedBlock), $currentVector); $currentVector = $this-\u003exorBytes($currentVector, $encryptedBlock); $result .= $temp; } if ($leftLength) { $currentVector = $this-\u003eencryptBlock($currentVector); $result .= $this-\u003exorBytes(substr($string, 8 * $i, $leftLength), $currentVector); } return $result; } protected function decryptTwelve($upperString) { $string = hex2bin(strtolower($upperString)); return openssl_decrypt($string, 'AES-128-CBC', $this-\u003eaesKey, OPENSSL_RAW_DATA, $this-\u003eaesIv); } } use FatSmallTools\\NavicatPassword; //需要指定版本，11或12 $navicatPassword = new NavicatPassword(12); //$navicatPassword = new NavicatPassword(11); //解密 //$decode = $navicatPassword-\u003edecrypt('15057D7BA390'); $decode = $navicatPassword-\u003edecrypt('266523D8991D6B48575B4C9F92F40BA6742967A9315D95CD4F1FEDB356C99FFC'); echo $decode.\"\\n\"; ","date":"2018-12-27","objectID":"/navicat%E8%A7%A3%E5%AF%86/:0:0","tags":["navicat"],"title":"02_navicat密码破解","uri":"/navicat%E8%A7%A3%E5%AF%86/"},{"categories":["spring"],"content":"Spring kafka 要点 以下内容记录了一些工作中遇到的kafka的要点（个人认为） ","date":"2019-10-27","objectID":"/10_springdata_kafka/:0:0","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["spring"],"content":"一、kafka消费者 ","date":"2019-10-27","objectID":"/10_springdata_kafka/:1:0","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["spring"],"content":"1.1、源码分析 1.1.1、 @EnableKafka 作用：kafka开启入口 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Import(KafkaBootstrapConfiguration.class) // 最重要的入口配置 public @interface EnableKafka { } 1.1.1.1、 KafkaBootstrapConfiguration 作用：kafka启动配置类，该类主要实例化以下两个Bean 1.1.1.1.1、 KafkaListenerAnnotationBeanPostProcessor 作用：实现BeanPostProcessor接口，重写方法 1.1.1.1.1.1、 postProcessAfterInitialization @Override public Object postProcessAfterInitialization(final Object bean, final String beanName) throws BeansException { if (!this.nonAnnotatedClasses.contains(bean.getClass())) { Class\u003c?\u003e targetClass = AopUtils.getTargetClass(bean); // 找到标记在类上的@KafkaListener注解 Collection\u003cKafkaListener\u003e classLevelListeners = findListenerAnnotations(targetClass); final boolean hasClassLevelListeners = classLevelListeners.size() \u003e 0; final List\u003cMethod\u003e multiMethods = new ArrayList\u003c\u003e(); // 找到标记在方法上的@KafkaListener注解 Map\u003cMethod, Set\u003cKafkaListener\u003e\u003e annotatedMethods = MethodIntrospector.selectMethods(targetClass, new MethodIntrospector.MetadataLookup\u003cSet\u003cKafkaListener\u003e\u003e() { @Override public Set\u003cKafkaListener\u003e inspect(Method method) { Set\u003cKafkaListener\u003e listenerMethods = findListenerAnnotations(method); return (!listenerMethods.isEmpty() ? listenerMethods : null); } }); if (hasClassLevelListeners) { Set\u003cMethod\u003e methodsWithHandler = MethodIntrospector.selectMethods(targetClass, (ReflectionUtils.MethodFilter) method -\u003e AnnotationUtils.findAnnotation(method, KafkaHandler.class) != null); multiMethods.addAll(methodsWithHandler); } if (annotatedMethods.isEmpty()) { this.nonAnnotatedClasses.add(bean.getClass()); if (this.logger.isTraceEnabled()) { this.logger.trace(\"No @KafkaListener annotations found on bean type: \" + bean.getClass()); } } else { // Non-empty set of methods for (Map.Entry\u003cMethod, Set\u003cKafkaListener\u003e\u003e entry : annotatedMethods.entrySet()) { Method method = entry.getKey(); for (KafkaListener listener : entry.getValue()) { // 重要的方法，处理kafkaListener processKafkaListener(listener, method, bean, beanName); } } if (this.logger.isDebugEnabled()) { this.logger.debug(annotatedMethods.size() + \" @KafkaListener methods processed on bean '\" + beanName + \"': \" + annotatedMethods); } } if (hasClassLevelListeners) { processMultiMethodListeners(classLevelListeners, multiMethods, bean, beanName); } } return bean; } 1.1.1.1.1.2、processKafkaListener protected void processKafkaListener(KafkaListener kafkaListener, Method method, Object bean, String beanName) { Method methodToUse = checkProxy(method, bean); // new endpoint实例，表示一个kafkaListener切入点 MethodKafkaListenerEndpoint\u003cK, V\u003e endpoint = new MethodKafkaListenerEndpoint\u003c\u003e(); endpoint.setMethod(methodToUse); // 处理Listener processListener(endpoint, kafkaListener, bean, methodToUse, beanName); } 1.1.1.1.1.3、processListener protected void processListener(MethodKafkaListenerEndpoint\u003c?, ?\u003e endpoint, KafkaListener kafkaListener, Object bean, Object adminTarget, String beanName) { String beanRef = kafkaListener.beanRef(); if (StringUtils.hasText(beanRef)) { this.listenerScope.addListener(beanRef, bean); } endpoint.setBean(bean); endpoint.setMessageHandlerMethodFactory(this.messageHandlerMethodFactory); endpoint.setId(getEndpointId(kafkaListener)); endpoint.setGroupId(getEndpointGroupId(kafkaListener, endpoint.getId())); endpoint.setTopicPartitions(resolveTopicPartitions(kafkaListener)); endpoint.setTopics(resolveTopics(kafkaListener)); endpoint.setTopicPattern(resolvePattern(kafkaListener)); endpoint.setClientIdPrefix(resolveExpressionAsString(kafkaListener.clientIdPrefix(), \"clientIdPrefix\")); String group = kafkaListener.containerGroup(); ... String concurrency = kafkaListener.concurrency(); ... resolveKafkaProperties(endpoint, kafkaListener.properties()); // 设置 KafkaListenerContainerFactory KafkaListenerContainerFactory\u003c?\u003e factory = null; String containerFactoryBeanName = resolve(kafkaListener.containerFactory()); ... endpoint.setBeanFactory(this.beanFactory); ... // 将endpoint 登记到 KafkaListenerEndpointRegistrar 中，前面一大段代码都是设置en","date":"2019-10-27","objectID":"/10_springdata_kafka/:1:1","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["spring"],"content":"1.1.3、 KafkaMessageListenerContainer KafkaMessageListenerContainer 该类封装了KafkaConsumer ，主要作用是连接kafka，并且poll数据，然后根据配置处理数据。 run 方法 @Override public void run() { this.consumerThread = Thread.currentThread(); if (this.genericListener instanceof ConsumerSeekAware) { ((ConsumerSeekAware) this.genericListener).registerSeekCallback(this); } if (this.transactionManager != null) { ProducerFactoryUtils.setConsumerGroupId(this.consumerGroupId); } this.count = 0; this.last = System.currentTimeMillis(); // 初始消费者线程绑定分区 initAsignedPartitions(); while (isRunning()) { try { // 拉取数据并且调用listener注解的业务方法处理数据 pollAndInvoke(); } catch (@SuppressWarnings(UNUSED) WakeupException e) { // Ignore, we're stopping } catch (NoOffsetForPartitionException nofpe) { this.fatalError = true; ListenerConsumer.this.logger.error(\"No offset and no reset policy\", nofpe); break; } catch (Exception e) { handleConsumerException(e); } catch (Error e) { // NOSONAR - rethrown Runnable runnable = KafkaMessageListenerContainer.this.emergencyStop; if (runnable != null) { runnable.run(); } this.logger.error(\"Stopping container due to an Error\", e); wrapUp(); throw e; } } wrapUp(); } pollAndInvoke 方法 protected void pollAndInvoke() { // 非自动提交并且(ack == COUNT || COUNT_TIME)，处理co if (!this.autoCommit \u0026\u0026 !this.isRecordAck) { // 该方法会提交ack，但是会判断是否该线程消费者线程，还会判断ack mode.只有非手动提交的这里才会提交。并且注意，提交线程一但提交，因为是多线程消费，会出现消费顺序不一致。 processCommits(); } // seek 指定消费者偏移量 processSeeks(); checkPaused(); // 开始拉取数据，指定超时时间 ConsumerRecords\u003cK, V\u003e records = this.consumer.poll(this.pollTimeout); this.lastPoll = System.currentTimeMillis(); checkResumed(); debugRecords(records); if (records != null \u0026\u0026 records.count() \u003e 0) { if (this.containerProperties.getIdleEventInterval() != null) { this.lastReceive = System.currentTimeMillis(); } // 调用@KafkaListener注解的业务代码，方法内部会判断是否有事务 invokeListener(records); } else { checkIdle(); } } ","date":"2019-10-27","objectID":"/10_springdata_kafka/:1:2","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["spring"],"content":"1.2 要点 多线徎多记录消费顺序会不一致，手动提交偏移量会导致数据数据丢失 一个@KafkaListener会启动concurrency个消费者；concurrency应该小于等于partitions数。 ","date":"2019-10-27","objectID":"/10_springdata_kafka/:2:0","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["spring"],"content":"引用 [1] spring-kafka源码解析 https://blog.csdn.net/qq_26323323/article/details/84938892 ","date":"2019-10-27","objectID":"/10_springdata_kafka/:3:0","tags":["kafka"],"title":"10_springdata_kafka","uri":"/10_springdata_kafka/"},{"categories":["测试工具"],"content":"测试工具gatling（加特林） 在学习Webflux响应式编程的过程中偶然听到了gatling这个负载测试工具，并且看着很简单。之前有听说过loadrunner和jmeter，并且使用过wrk这个小工具，但是没有一个详细完整的报告。因此看到这个工具的时候，就花了点时间在网上找资料学习了一下。这个文档只是为了记录我的学习过程。我是开发人员，因此不会关注太细，如有问题，请指正。 ","date":"2019-10-27","objectID":"/gatling/:0:0","tags":["test"],"title":"gatling测试工具用法介绍","uri":"/gatling/"},{"categories":["测试工具"],"content":"1、使用方式一 下载 Download - Gatling Load and Performance testing 目录结构 bin //命令 conf //配置文件 lib //类库 results //测试之后生成的报告地址 target 测试脚本编译目录 user-files //脚本目录 resource 脚本数据资源文件 simulations 脚本文件，脚本下文件目录以package方式 下载完成之后simulations下有样例文件user-files/simulations/computerdatabase/BasicSimulation.scala 执行样例 sh gatling.sh 执行之后可以选择需要执行的脚本。最后会在results下生成测试报告 ","date":"2019-10-27","objectID":"/gatling/:1:0","tags":["test"],"title":"gatling测试工具用法介绍","uri":"/gatling/"},{"categories":["测试工具"],"content":"2、使用方式二 方式二使用的maven进行测试，个人觉得这种方式更适合，代码可调试。比下载工具方式更简单 使用idea下载scala插件 下载完成新建maven项目,如图配置 最新参见:Maven Repository: io.gatling.highcharts » gatling-highcharts-maven-archetype GroupId:io.gatling.highcharts ArtifactId:gatling-highcharts-maven.archetype Version:3.0.2 ├── pom.xml ├── src │ └── test │ ├── resources │ │ ├── bodies │ │ ├── data │ │ ├── gatling.conf │ │ ├── logback.xml │ │ └── recorder.conf │ └── scala │ ├── BasicSimulation.scala //源码文件 │ ├── Engine.scala //执行文件 │ ├── IDEPathHelper.scala │ └── Recorder.scala └── target 不使用artifact直接使用插件 如下： \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eio.gatling.highcharts\u003c/groupId\u003e \u003cartifactId\u003egatling-charts-highcharts\u003c/artifactId\u003e \u003cversion\u003e3.0.2\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eio.gatling\u003c/groupId\u003e \u003cartifactId\u003egatling-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e3.0.2\u003c/version\u003e \u003cconfiguration\u003e \u003csimulationsFolder\u003esrc/main/java\u003c/simulationsFolder\u003e \u003csimulationClass\u003ecom.scemsjyd.BaseSimulation\u003c/simulationClass\u003e \u003c/configuration\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cphase\u003etest\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003eexecute\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003cjvmArgs\u003e \u003cjvmArg\u003e-Dgatling.http.ahc.connectTimeout=6000000\u003c/jvmArg\u003e \u003cjvmArg\u003e-Dgatling.http.ahc.requestTimeout=6000000\u003c/jvmArg\u003e \u003cjvmArg\u003e-Dgatling.http.ahc.sslSessionTimeout=6000000\u003c/jvmArg\u003e \u003cjvmArg\u003e-Dgatling.http.ahc.pooledConnectionIdleTimeout=6000000\u003c/jvmArg\u003e \u003cjvmArg\u003e-Dgatling.http.ahc.readTimeout=6000000\u003c/jvmArg\u003e \u003c/jvmArgs\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ","date":"2019-10-27","objectID":"/gatling/:2:0","tags":["test"],"title":"gatling测试工具用法介绍","uri":"/gatling/"},{"categories":["中间件"],"content":"sentry配置 使用sentry 进行异常报警 sentry安装 sentry 目前推荐使用docker安装，docker-compose启动 官方安装链接：https://docs.sentry.io/server/installation 添加maven依赖 \u003cdependency\u003e \u003cgroupId\u003ecom.getsentry.raven\u003c/groupId\u003e \u003cartifactId\u003eraven-logback\u003c/artifactId\u003e \u003cversion\u003e8.0.3\u003c/version\u003e \u003c/dependency\u003e 配置logback \u003cappender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"\u003e \u003cdsn\u003ehttps://username:password@sentry.abc.com/117\u003c/dsn\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"\u003e \u003clevel\u003eERROR\u003c/level\u003e \u003c/filter\u003e \u003c/appender\u003e ","date":"2018-11-27","objectID":"/sentry/:0:0","tags":["sentry"],"title":"sentry在java中用法","uri":"/sentry/"},{"categories":["中间件"],"content":"skywalking-agent源码分析 ","date":"2018-09-27","objectID":"/skywalking/:0:0","tags":["apm"],"title":"skywalking源码分析","uri":"/skywalking/"},{"categories":["中间件"],"content":"执行顺序图 该顺序图大体内容都有了，缺少最后一步的BootService的生命周期调用，即下面的接口。在这个接口中会有一些服务调用，比如向Gprc注册发送的流程* public interface BootService { void prepare() throws Throwable; void boot() throws Throwable; void onComplete() throws Throwable; void shutdown() throws Throwable; } ","date":"2018-09-27","objectID":"/skywalking/:1:0","tags":["apm"],"title":"skywalking源码分析","uri":"/skywalking/"},{"categories":["中间件"],"content":"分析 分析中主要讲class Transformer implements AgentBuilder.Transformer这个实现类中的transform方法 transform方法中调用pluginFinder的find方法。 @Override public DynamicType.Builder\u003c?\u003e transform(DynamicType.Builder\u003c?\u003e builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) { List\u003cAbstractClassEnhancePluginDefine\u003e pluginDefines = pluginFinder.find(typeDescription, classLoader); if (pluginDefines.size() \u003e 0) { DynamicType.Builder\u003c?\u003e newBuilder = builder; EnhanceContext context = new EnhanceContext(); for (AbstractClassEnhancePluginDefine define : pluginDefines) { DynamicType.Builder\u003c?\u003e possibleNewBuilder = define.define(typeDescription, newBuilder, classLoader, context); if (possibleNewBuilder != null) { newBuilder = possibleNewBuilder; } } if (context.isEnhanced()) { logger.debug(\"Finish the prepare stage for {}.\", typeDescription.getName()); } return newBuilder; } logger.debug(\"Matched class {}, but ignore by finding mechanism.\", typeDescription.getTypeName()); return builder; } 找到所有的AbstractClassEnhancePluginDefine实现类，在迭代所有子类，调用子类的define方法。在define方法中最主要的方法是enhance。该方法是抽象方法，由子类ClassEnhancePluginDefine中调用enhanceClass和enhanceInstance。 @Override protected DynamicType.Builder\u003c?\u003e enhance(TypeDescription typeDescription, DynamicType.Builder\u003c?\u003e newClassBuilder, ClassLoader classLoader, EnhanceContext context) throws PluginException { newClassBuilder = this.enhanceClass(typeDescription, newClassBuilder, classLoader); newClassBuilder = this.enhanceInstance(typeDescription, newClassBuilder, classLoader, context); return newClassBuilder; } 调用enhanceClass方法。该方法第一步也是最主要的一步调用getStaticMethodsInterceptPoints。这个方法也是抽象方法。这个方法由具体的插件实现。比如LoadBalancedConnectionProxyInstrumentation。这个类中会调用getConstructorsInterceptPoints来获取哪些方法是需要被拦截的。并且通过getMethodsInterceptor方法返回具体的实现类。这个方法类似AOP做切面处理。 private DynamicType.Builder\u003c?\u003e enhanceClass(TypeDescription typeDescription, DynamicType.Builder\u003c?\u003e newClassBuilder, ClassLoader classLoader) throws PluginException { StaticMethodsInterceptPoint[] staticMethodsInterceptPoints = getStaticMethodsInterceptPoints(); String enhanceOriginClassName = typeDescription.getTypeName(); if (staticMethodsInterceptPoints == null || staticMethodsInterceptPoints.length == 0) { return newClassBuilder; } for (StaticMethodsInterceptPoint staticMethodsInterceptPoint : staticMethodsInterceptPoints) { String interceptor = staticMethodsInterceptPoint.getMethodsInterceptor(); if (StringUtil.isEmpty(interceptor)) { throw new EnhanceException(\"no StaticMethodsAroundInterceptor define to enhance class \" + enhanceOriginClassName); } if (staticMethodsInterceptPoint.isOverrideArgs()) { newClassBuilder = newClassBuilder.method(isStatic().and(staticMethodsInterceptPoint.getMethodsMatcher())) .intercept( MethodDelegation.withDefaultConfiguration() .withBinders( Morph.Binder.install(OverrideCallable.class) ) .to(new StaticMethodsInterWithOverrideArgs(interceptor)) ); } else { newClassBuilder = newClassBuilder.method(isStatic().and(staticMethodsInterceptPoint.getMethodsMatcher())) .intercept( MethodDelegation.withDefaultConfiguration() .to(new StaticMethodsInter(interceptor)) ); } } return newClassBuilder; } LoadBalancedConnectionProxyInstrumentation的实现方法 @Override protected StaticMethodsInterceptPoint[] getStaticMethodsInterceptPoints() { return new StaticMethodsInterceptPoint[] { new StaticMethodsInterceptPoint() { @Override public ElementMatcher\u003cMethodDescription\u003e getMethodsMatcher() { return named(\"createProxyInstance\"); } //返回具体的拦截器实现类 @Override public String getMethodsInterceptor() { return METHOD_INTERCEPTOR; } @Override public boolean isOverrideArgs() { return false; } } }; } 调用enhanceInstance方法。这个方法中最主要的是调用下面的两个方法，一个是对构造器进行切面拦截，另一个是对实例对象中的方法进行拦截。比如InvocableHandlerInstrumentation这个实现类是对Springmvc中InvocableHandlerMethod的invokeForRequest进行拦截，具体的拦截器类是org.apache.skywalking.apm.plugin.spring.mvc.commons.interceptor.InvokeForRequestInterceptor。 ConstructorInterceptPoint[] constructorInterceptPoints = getConstructorsInterceptPoints(); InstanceMethodsInt","date":"2018-09-27","objectID":"/skywalking/:2:0","tags":["apm"],"title":"skywalking源码分析","uri":"/skywalking/"},{"categories":["中间件"],"content":"总结重要实现及接口 该流程过程中主要是在enhance方法内进程代理（拦截器）的创建。具体的拦截器接口有InstanceConstructorInterceptor,InstanceMethodsAroundInterceptor,StaticMethodsAroundInterceptor,然后在上面三个接口的子类中有些会实现EnhancedInstance接口进行动态属性添加。而最主要的三个接口的实现类的调用是通过newClassBuilder.method(junction).intercept方法内部调用的。 如下图： ","date":"2018-09-27","objectID":"/skywalking/:3:0","tags":["apm"],"title":"skywalking源码分析","uri":"/skywalking/"},{"categories":["java基础"],"content":"ClassLoader 介绍 ","date":"2017-10-27","objectID":"/classloader/:0:0","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"什么是ClassLoader java源码编译出来是一个个的.class文件，而ClassLoader的作用是将一个个的.class文件加载到jvm中。 ","date":"2017-10-27","objectID":"/classloader/:1:0","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"ClassLoader加载机制 Java中默认提供了三个ClassLoader BootStrap ClassLoader Extension ClassLoader App ClassLoader ","date":"2017-10-27","objectID":"/classloader/:2:0","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"BootStrap ClassLoader 启动类加载器 作用：java中是最顶层的加载器，负责加载jdk的核心类库：rt.jar、resources.jar、charsets.jar public class BootStrapTest { public static void main(String[] args) { URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs(); for (int i = 0; i \u003c urls.length; i++) { System.out.println(urls[i].toExternalForm()); } } } 以上程序可以得到BootStrap ClassLoader从哪些地址加载了哪些jar包 file://Users/xxx/java/jdk1.8.0_60/jre/lib/resources.jar file://Users/xxx/java/jdk1.8.0_60/jre/lib/rt.jar file://Users/xxx/java/jdk1.8.0_60/jre/lib/sunrsasign.jar file://Users/xxx/java/jdk1.8.0_60/jre/lib/jsse.jar file://Users/xxx/java/jdk1.8.0_60/jre/lib/charsets.jar file://Users/xxx/java/jdk1.8.0_60/jre/lib/jfr.jar file://Users/xxx/java/jdk1.8.0_60/jre/classes 该结果和System.out.println(System.getProperty(\"sun.boot.class.path\"));输出结果一致 ","date":"2017-10-27","objectID":"/classloader/:2:1","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"Extension ClassLoader 扩展类加载器 作用：负责加载java的扩展类库，默认加载$JAVA_HOME/jre/lib/ext/目录下的所有jar ","date":"2017-10-27","objectID":"/classloader/:2:2","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"App ClassLoader 系统类加载器 作用：负责加载classpath目录下的所有jar和class文件。主要负责加载程序员自己编码的java应用代码 可以通过ClassLoader.getSystemClassLoader()方法获取 除了以上三种加载器之外，程序员可以自己实现自定义加载器，方式：继承java.lang.ClassLoader类。比如使用该方式可以对源class文件进行混淆加密，通过自定义ClassLoader进行解密 默认三种加载器之前存在父子关系（注意不是继承）AppClassLoader -\u003e ExtensionClassLoader -\u003e BootStrapClassLoader 。通过getParent()方法获取父类加载器（父类加载器使用包含关系引用） ","date":"2017-10-27","objectID":"/classloader/:2:3","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"ClassLoader加载原理 摘自https://zhuanlan.zhihu.com/p/25493756 ","date":"2017-10-27","objectID":"/classloader/:3:0","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"原理介绍 ClassLoader使用的是双亲委托模型来搜索类的，每个ClassLoader实例都有一个父类加载器的引用（不是继承的关系，是一个包含的关系），虚拟机内置的类加载器（Bootstrap ClassLoader）本身没有父类加载器，但可以用作其它ClassLoader实例的的父类加载器。当一个ClassLoader实例需要加载某个类时，它会试图亲自搜索某个类之前，先把这个任务委托给它的父类加载器，这个过程是由上至下依次检查的，首先由最顶层的类加载器Bootstrap ClassLoader试图加载，如果没加载到，则把任务转交给Extension ClassLoader试图加载，如果也没加载到，则转交给App ClassLoader 进行加载，如果它也没有加载得到的话，则返回给委托的发起者，由它到指定的文件系统或网络等URL中加载该类。如果它们都没有加载到这个类时，则抛出ClassNotFoundException异常。否则将这个找到的类生成一个类的定义，并将它加载到内存当中，最后返回这个类在内存中的Class实例对象。 ","date":"2017-10-27","objectID":"/classloader/:3:1","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"为什么使用双亲委托模型？ 因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要 ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 ","date":"2017-10-27","objectID":"/classloader/:3:2","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["java基础"],"content":"但是JVM在搜索类的时候，又是如何判定两个class是相同的呢？ JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM才认为这两个class是相同的。就算两个class是同一份class字节码，如果被两个不同的ClassLoader实例所加载，JVM也会认为它们是两个不同class。比如网络上的一个Java类org.classloader.simple.NetClassLoaderSimple，javac编译之后生成字节码文件NetClassLoaderSimple.class，ClassLoaderA和ClassLoaderB这两个类加载器并读取了NetClassLoaderSimple.class文件，并分别定义出了java.lang.Class实例来表示这个类，对于JVM来说，它们是两个不同的实例对象，但它们确实是同一份字节码文件，如果试图将这个Class实例生成具体的对象进行转换时，就会抛运行时异常java.lang.ClassCaseException，提示这是两个不同的类型。现在通过实例来验证上述所描述的是否正确： ","date":"2017-10-27","objectID":"/classloader/:3:3","tags":["classloader"],"title":"classloader简要概述","uri":"/classloader/"},{"categories":["运维"],"content":"iptables 简单入门介绍 iptables 是组成Linux平台下的包过滤防火墙。提到iptables就不能不提到netfliter。这里可以简单理解iptables是客户端，而真正进行包过滤的是内核中的netfliter组件。 ","date":"2017-09-27","objectID":"/iptables/:0:0","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"一、网络基础知识 ","date":"2017-09-27","objectID":"/iptables/:1:0","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"1.1、网络分层模型 还有一个四层模型，是将五层模型中的数据链路及物理层合并为网络接口层(链路层) 物理层：主要负责在物理载体上的数据包传输，如 WiFi，以太网，光纤，电话线等。 数据链路层：主要负责链路层协议解析（主要为以太网帧）。 网络层：主要负责 IP 协议（包括 IPv4 和 IPv6）解析。 传输层：负责传输层协议解析（主要为 TCP，UDP 等） 应用层：传输层以上我们均归类为应用层，主要包括各类应用层协议，如我们常用的 HTTP，FTP，SMTP，DNS，DHCP 等。 ","date":"2017-09-27","objectID":"/iptables/:1:1","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"1.2、几种网络协议 TCP/IP 是互联网。≤相关的各类协议族的总称，比如：TCP，UDP，IP，FTP，HTTP，ICMP，SMTP 等都属于 TCP/IP 族内的协议。 ICMP：网际报文控制协议，比如常用的ping命令，traceroute命令 用于IP主机、路由器之间传递控制消息。控制消息是在网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然不传输用户数据，但是对于用户数据的传递起着重要的作用。 IGMP：互联网组管理协议。 IP组播通信的特点是报文从一个源发出，被转发到一组特定的接收者。但在组播通信模型中，发送者不关注接收者的位置信息，只是将数据发送到约定的目的组播地址。要使组播报文最终能够到达接收者，需要某种机制使连接接收者网段的组播路由器能够了解到该网段存在哪些组播接收者，同时保证接收者可以加入相应的组播组中。IGMP就是用来在接收者主机和与其所在网段直接相邻的组播路由器之间建立、维护组播组成员关系的协议。 ARP/RARP：地址解析协议/反地址解析协议。 根据IP地址获取物理地址/根据物理地址获取IP地址，同一局域网下网络传输使用。 TCP：传输控制协议 三次握手，四次挥手。面向有连接，可靠传输 UDP：用户数据报协议 无连接，不可靠 UDP TCP 是否连接 无连接 面向连接 是否可靠 不可靠传输，不使用流量控制和拥塞控制 可靠传输，使用流量控制和拥塞控制 连接对象个数 支持一对一，一对多，多对一和多对多交互通信 只能是一对一通信 传输方式 面向报文 面向字节流 首部开销 首部开销小，仅8字节 首部最小20字节，最大60字节 适用场景 适用于实时应用（IP电话、视频会议、直播等） 适用于要求可靠传输的应用，例如文件传输 ","date":"2017-09-27","objectID":"/iptables/:1:2","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"二、Iptables/netfliter 要学会使用iptables和理解netfliter，就必须弄懂数据包在设备上的传输流程，及在每一个阶段所能做的事。 ","date":"2017-09-27","objectID":"/iptables/:2:0","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"2.1、Packet传输流程图 ","date":"2017-09-27","objectID":"/iptables/:2:1","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"2.2、iptables 表（tables） filter：一般的过滤功能 nat：用于nat功能（端口映射，地址映射等） mangle：用于对特定数据包的修改 Raw：有限级最高，设置raw时一般是为了不再让iptables做数据包的链接跟踪处理，提高性能RAW 表只使用在PREROUTING链和OUTPUT链上,因为优先级最高，从而可以对收到的数据包在连接跟踪前进行处理。一但用户使用了RAW表,在某个链 上,RAW表处理完后,将跳过NAT表和 ip_conntrack处理,即不再做地址转换和数据包的链接跟踪处理了。RAW表可以应用在那些不需要做nat的情况下，以提高性能。如大量访问的web服务器，可以让80端口不再让iptables做数据包的链接跟踪处理，以提高用户的访问速度。 链（chains） PREROUTING：数据包进入路由表之前 INPUT：通过路由表后目的地为本机 FORWARD：通过路由表后，目的地不为本机 OUTPUT：由本机产生，向外转发 POSTROUTIONG：发送到网卡接口之前 规则（rules） *nat :PREROUTING ACCEPT [60:4250] :INPUT ACCEPT [31:1973] :OUTPUT ACCEPT [3:220] :POSTROUTING ACCEPT [3:220] -A PREROUTING -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.1.160:80 //PREROUTING规则都放在上面 -A PREROUTING -p tcp -m tcp --dport 33066 -j DNAT --to-destination 192.168.1.161:3306 -A POSTROUTING -d 192.168.1.160/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.168.1.7 //POSTROUTING规则都放在下面 -A POSTROUTING -d 192.168.1.161/32 -p tcp -m tcp --sport 3306 -j SNAT --to-source 192.168.1.7 ..... *filter :INPUT ACCEPT [16:7159] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [715:147195] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8088 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 33066 -j ACCEPT ","date":"2017-09-27","objectID":"/iptables/:2:2","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"2.3、使用 iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］ 查看iptables命令 iptables --help 2.3.1、操作filter表 禁用ping iptables -t filter -A INPUT -p icmp --icmp-type 8 -s 0.0.0.0/0 -j DROP 开通一段ip的端口 iptables -t filter -I YZW -m iprange --src-range 192.168.110.236-192.168.110.237 -p tcp -m multiport --dport 3011,3012,3301,8005,3302,3015,3016,20930 -j ACCEPT 保存iptables iptables-save \u003e /etc/sysconfig/iptables-yzw 2.3.2、操作nat表 比如访问本机（192.168.1.7）的8088端口转发到192.168.1.160的80端口； DNAT iptables -t nat -A PREROUTING -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.1.160:80 SNAT iptables -t nat -A POSTROUTING -d 192.168.1.160/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.168.1.7 MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.1.7/255.255.255.0 -o eth0 -j MASQUERADE ","date":"2017-09-27","objectID":"/iptables/:2:3","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["运维"],"content":"引用 【1】Iptables 规则用法小结 【2】状态机制 ","date":"2017-09-27","objectID":"/iptables/:3:0","tags":["iptables"],"title":"iptables入门","uri":"/iptables/"},{"categories":["java基础"],"content":"HashMap源码解析 ","date":"2016-04-27","objectID":"/hashmap/:0:0","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"构造方法 ==无参构造方法== /** * Constructs an empty \u003ctt\u003eHashMap\u003c/tt\u003e with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } 看方法注释可知：无参构造方法默认capacity = 16 、loadFactor = 0.75 ==带有初始容量的构造方法== /** * Constructs an empty \u003ctt\u003eHashMap\u003c/tt\u003e with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } 初始容量负数扔IllegalArgumentException异常，loadFactor = 0.75 ==带有初始容量及负载因子的构造方法== /** * Constructs an empty \u003ctt\u003eHashMap\u003c/tt\u003e with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u003c 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity \u003e MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u003c= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } static final int MAXIMUM_CAPACITY = 1 \u003c\u003c 30; ==另一个Map作为参数== /** * Constructs a new \u003ctt\u003eHashMap\u003c/tt\u003e with the same mappings as the * specified \u003ctt\u003eMap\u003c/tt\u003e. The \u003ctt\u003eHashMap\u003c/tt\u003e is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified \u003ctt\u003eMap\u003c/tt\u003e. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map\u003c? extends K, ? extends V\u003e m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } ","date":"2016-04-27","objectID":"/hashmap/:1:0","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"tableSizeFor 返回大于输入参数且最近的2的整数次幂的数。比如10，则返回16。 参考https://www.jianshu.com/p/cbe3f22793be /** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u003e\u003e\u003e 1; n |= n \u003e\u003e\u003e 2; n |= n \u003e\u003e\u003e 4; n |= n \u003e\u003e\u003e 8; n |= n \u003e\u003e\u003e 16; return (n \u003c 0) ? 1 : (n \u003e= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 通过无符号右移再异或取到高位全是1，最后再加1. ","date":"2016-04-27","objectID":"/hashmap/:2:0","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"put 存放值 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } ","date":"2016-04-27","objectID":"/hashmap/:3:0","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"hash(key) 求key的hash值 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); } (h = key.hashCode()) ^ (h »\u003e 16) 为什么需要h »\u003e 16位？扰动函数，减轻了哈希冲突 ","date":"2016-04-27","objectID":"/hashmap/:3:1","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"putValue ","date":"2016-04-27","objectID":"/hashmap/:3:2","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["java基础"],"content":"resize ","date":"2016-04-27","objectID":"/hashmap/:3:3","tags":["hashmap"],"title":"HashMap源码分析","uri":"/hashmap/"},{"categories":["中间件"],"content":"《redis设计与实现》学习记录（一） 一直在使用redis，使用熟练，但是好像一直没有关注过底层如何实现，最近准备关注一下底层的数据结构，于是买了本《redis设计与实现》第二版，晚上睡前抽时间看看，让自己在脑海中对redis有一个更清晰的认识。以下内容是自己看书的一些记录。因此有些内容摘自书中。 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:0:0","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"数据结构 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:0","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"字符串 redis自定义了自己的字符串数据结构。（SDS=简单动态字符串） struct{ int len;//所保存的字符数长度 int free;//未使用字节数量 char buf[];//用于保存字符串，并且使用‘\\0’结尾，与c保持一致，方便使用c的部分函数 } 优势 获取字符串长度（STRLEN函数）时间复杂度为O(1)，因为有len这个属性。而C语言没有这个属性，要获取长度需要遍历数组。 杜绝缓冲区溢出或者泄露：当字符串拼接或者添加时，C语言默认字符数组容量足够，而SDS会默认检查free是否足够。 空间预分配：对字符串增加，如果SDS.len小于1M,分配free和len同样大小的空间；如果\u003e1M，将分配1M的free空间。 惰性空间释放：缩减SDS，并且立即释放内存，而是将释放大小增加到free空间。不用担心内存浪费，因为SDS提供了api在真正需要释放空间时执行。 目的：减小频繁的内存分配，即减小了程序的时间开销，增加性能。 二进制安全：C以‘\\0’为结尾，如果存储二进制图片等数据会认为‘\\0’即结束。但是SDS有一个len属性，会读取len属性大小（+1）的长度才会结束，即安全的二进制存储。 兼容部分C语言函数：SDS同样以‘\\0’结尾，即遵询了部分C的结构，可以重用部分C函数，不必重写。 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:1","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"链表 自定义链表结构： typedef struct listNode{ struct listNode *prev;//前置节点 struct listNode *next;//后置节点 void *value;//链表结点数据 }listNode; typedef struct list{ listNode *head;//头节点 listNode *tail;//尾节点 unsigned long len;//链表节点数量 void *(*dup)(void *ptr);//节点复制函数 void *(*free)(void *ptr);//节点释放函数 int (*match)(void *ptr,void *key);//节点对比函数 }list; 优势： 双端链表：获取前置节点与后置节点时间复杂度O(1)，通过prev和next指针。 无环：next=null即尾节点，prev=null即头节点 链表长度计数器：len属性获取节点长度时间复杂度O(1) 多态：可以根据value的类型为内置的三个函数指向具体类型的函数。如value是string,则三个函数为操作string的函数。 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:2","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"字典 redis字典使用哈希表为底层实现。一个哈希表里有多个hash节点，一个节点保存一个k-v（键值对） typedef struct dictht{ //dict hash table dictEntry **table;//哈希表 *数组* unsigned long size;//哈希表大小 unsigned long sizemask;//hash table大小掩码，计算索引值,总等于size-1,用户计算键放于table哪个索引上 unsigned long used;//hash table已使用节点大小 }dictht; typedef struct dictEntry{ void *key;//键 union{ void *val; uint64_tu64; int64_ts64; }v; //值 struct dictEntry *next; //指向下个哈希表节点，形成链表。拉链表解决hash冲突。 } typedef struct dict{ dictType *type; //类型特定函数 void *privdaa;//私有数据 dictht ht[2]; // 哈希表，大小为2，一个存储，另一个用于rehash时 in rehashidx; //rehash 索引，不rehash 值 = -1 } type属性和privdata属性，用于不同类型设置不同的函数 ht 大小为2，ht[1]只会在对ht[0]进行rehash时使用 使用了链地址法解决hash冲突dictEntry.next指针存储下一个节点 rehash 扩展操作：为ht[1]分配ht[0].used * 2的2^n 收缩操作：为ht[1]分配ht[0].used 的2^n 时机，以下任一个满足： 服务器没有执行BGSAVE或者BGREWRITEAOF，并且load_factor\u003e=1 正在执行BGSAVE或者BGREWRITEAOF，并且load_factor\u003e=5 load_factor = ht[0].used / ht[0].size Load_facotr \u003c 0.1自动执行收缩 rehash并不是一次性完成，而是多次，激进式完成。避免当数据量大时，计算量导致停止服务。 rehash时的查询先ht[0]再ht[1],新增直接操作ht[1] ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:3","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"跳跃表 跳跃表（skiplist）是一种有序数据结构。平均O(logN)、最坏O(N)时间复杂度。redis使用跳跃表作为有序集成键的底层实现之一。 typedef struct zskiplistNode{ struct zskiplistLevel{ struct zskiplistNode *forward;//前进指针 unsigned int span;//跨度 }level[]; //层 struct zskiplistNode *backward; double score;//分值 robj *obj; }zskiplistNode; typedef struct zskiplist{ struct skiplistNode *header,*tail;//头尾指针 unsigned long length; int level; } 跳跃表是有序集合的底层实现之一 zskiplist保存跳跃表信息，zskiplistNode保存节点信息 跳跃表按照分值大小排序 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:4","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"整数集合（intset） 整数集合是redis保存整数值的集合底层数据结构。 typedef struct intset{ uint32_t encoding;//编码方式 uint32_t length;//集合元素个数 int8_t contents[];//保存的元素 }intset; 虽然intset的content属性类型为int8_t，但是content并不保存int8_t类型的值，而是取决于encoding类型的值。 升级：当向contents添加一个类型比当前值的最大类型还大时，比如现在存放int16型的数据，但是下一个存放int32类型数据，那么intset集合会先进行升级。扩展contents的底层数据字节长度，再把之前的值改变成新的字节长度。最后更改encoding编码。因此intset添加元素的时间复杂度为O(N) 不支持降级 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:5","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"压缩列表 压缩列表是列表键及哈希键的底层实现之一，当列表键少量并且是小整数或者短字符时使用。 zlbytes表示压缩列表占用内存总字节数 zltail表示压缩列表表尾距离开始节点的偏移量 zllen表示节点数量 entry节点数据 zlend标记压缩列表结尾 压缩列表节点数据结构，即上图的entry节点： 描述： Previous_entry_length前一节点的长度，如果是\u003c 254字节，使用1字节长保存，如果\u003e=254字节，使用5字节保存，并且属性第一字节设置为OxFE=254。 encoding content内容的编码 content 真正保存的内容 影响 ： 压缩列表会引起连锁更新：因为previous_entry_length保存了前一个节点的长度。如果介于250~254之前，新增一个节点在前面并且是大于254的，接下来的节点的previous_entry_length会调整为5字节，又会影响下一个节点，连锁反应。 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:1:6","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"对象 redis并不直接使用上面的提到的数据结构来构建数据库。而是使用上面提到的数据结构构建了五种redis对象：字符串对象 列表对象 哈希对象 集合对象 有序集合对象。 使用对象的好处是可以对同一种对象底层使用不同的实现。并且根据对象类型执行不同的命令。优化对象在不同的场景下的使用效率。 redis对象实现了引用计数对内存进行回收。同时实现了对象的共享，以实现内存的节约。 redis对象带有访问时间记录信息，lru等属性，用于回收最近最少使用的对象。 typedef struct redisObject{ unsigned type:4; //对象类型 unsigned encodeing:4; //编码 void *ptr; //指向底层实现该对象的数据结构指针 }robj; type值有5种类型常量，分别对应redis的5种对象。 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 可以使用type命令返回redis对象的值类型 set msg \"hello world\" type msg //返回string ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:0","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"编码和底层编码 对象的ptr指针指向了具体该对象的实现数据结构，而数据结构邮对象的encoding决定. 编码常量 编码对象底层数据结构 OBJECT ENCODING命令输出 REDIS_ENCODING_INT long类型整数 int REDIS_ENCODING_EMBSTR embtr编码的SDS embstr REDIS_ENCODING_RAW SDS raw REDIS_ENCODING_HT 字典 hashtable REDIS_ENCODING_LINKEDLIST 双端列表 linkedlist REDIS_ENCODING_ZIPLIST 压缩列表 ziplist REDIS_ENCODING_INTSET 整数集合 intset REDIS_ENCODING_SKIPLIST 跳跃表 skiplist ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:1","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"字符串对象 字符串对象编码可以是int、raw、embstr。 如果字符串对象保存的值类型为整数，那么encoding=REDIS_ENCODING_INT 如何值为字符串值，并且字符串值length \u003e 32 byte 那么encoding = REDIS_ENCODING_RAW。 相反如果length \u003c= 32 byte encoding = REDIS_ENCODING_EMBSTR 类型的编码不是永恒不变的，当原来保存的是int值，但是使用了APPEND函数添加了字符串，那么类型将变成raw。为什么不是embstr，是因为embstr没有修改函数，只有先将其转为raw才能执行修改操作。 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:2","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"列表对象 列表对象的编码可以是ziplist或者linkedlist 使用ziplist的条件如下： 列表对象保存的所有字符串元素长度 \u003c 64 byte 列表对象保存的元素数量 \u003c 512个 除此之外都使用linkedlist结构。 可以修改配置：list-max-ziplist-value 和list-max-ziplist-entries来修改上面的条件 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:3","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"哈希对象 哈希对象的编码是ziplist和hashtable 使用ziplist条件如下： 所有键值对的length \u003c 64 byte 所有键值对的数据\u003c 512 除此之外使用hashtable 可以修改配置：hash-max-ziplist-value 和hash-max-ziplist-entries来修改上面的条件 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:4","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"集合对象 集合对象使用的编码是：intset和hashtable 使用intset条件如下： 集合对象保存的所有元素都是整数 集合对象保存的元素个数 \u003c= 512 除此之外使用hashtable 可以修改配置：set-max-intset-value来修改上面的条件 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:5","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":["中间件"],"content":"有序集合对象 有序集合对象编码是：ziplist和skiplist 使用ziplist条件如下： 有序集合保存元素个数 \u003c 128 有序集合保存的所有元素长度 \u003c 64 byte 除此之外使用skiplist编码 可以修改配置：zset-max-ziplist-value 和zset-max-ziplist-entries来修改上面的条件 ","date":"2018-01-27","objectID":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/:2:6","tags":["redis"],"title":"01_redis设计与实现","uri":"/01_redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"技能清单 熟练使用Java语言，熟悉golang和shell脚本开发 熟练掌握多线程开发，曾多次解决线上多线程问题 熟悉常见设计模式（单例、工厂、策略、模板、装饰、代理等） 熟悉主流web开发框架：springboot、mybatis、springmvc等 熟悉常见的中间件，比如redis、xxl-job、rabbitmq、kafka、elasticsearch等 熟悉微服务开发，dubbo、springcloud 熟悉JVM，能使用jdk提供的常见工具（jstack、jmap、jstat）并曾多次对线上问题进行排查和提供解决方案 熟悉Mysql，知道常见的SQL优化方式 熟悉HTML，CSS，JavaScript，vue，webpack等常用的web前端开发技术 熟悉docker及dockerfile的编写 熟练使用git，和jenkins配置及部署 了解k8s生态，大数据hadoop及其生态 学的太杂，还有很多… 联系方式 Email：scemsjyd@gmail.com Location：四川成都 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"}]